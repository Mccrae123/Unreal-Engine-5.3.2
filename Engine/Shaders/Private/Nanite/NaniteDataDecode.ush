// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "../Common.ush"
#include "../SceneData.ush"

#define USE_IMPLICIT_TANGENT_SPACE				1														// must match define in NaniteBuilder.cpp
#define USE_CONSTRAINED_CLUSTERS				1														// must match define in NaniteBuilder.h

#define MAX_STREAMING_REQUESTS					( 128u * 1024u )										// must match define in NaniteResources.h
#define MAX_CLUSTER_TRIANGLES					128
#define MAX_CLUSTER_VERTICES					256
#define MAX_NANITE_UVS							4														// must match define in NaniteResources.h

#define USE_STRIP_INDICES						1														// must match define in NaniteResources.h

#define CLUSTER_PAGE_GPU_SIZE_BITS				17														// must match define in NaniteResources.h
#define CLUSTER_PAGE_GPU_SIZE					( 1 << CLUSTER_PAGE_SIZE_BITS )							// must match define in NaniteResources.h
#define MAX_CLUSTERS_PER_PAGE_BITS				11														// must match define in NaniteResources.h
#define MAX_CLUSTERS_PER_PAGE_MASK				( ( 1 << MAX_CLUSTERS_PER_PAGE_BITS ) - 1 )				// must match define in NaniteResources.h
#define MAX_CLUSTERS_PER_PAGE					( 1 << MAX_CLUSTERS_PER_PAGE_BITS )						// must match define in NaniteResources.h
#define MAX_CLUSTERS_PER_GROUP_BITS				9														// must match define in NaniteResources.h
#define MAX_CLUSTERS_PER_GROUP_MASK				( ( 1 << MAX_CLUSTERS_PER_GROUP_BITS ) - 1 )			// must match define in NaniteResources.h
#define MAX_CLUSTERS_PER_GROUP					( ( 1 << MAX_CLUSTERS_PER_GROUP_BITS ) - 1 )			// must match define in NaniteResources.h
#define MAX_HIERACHY_CHILDREN_BITS				6														// must match define in NaniteResources.h
#define MAX_HIERACHY_CHILDREN					( 1 << MAX_HIERACHY_CHILDREN_BITS )						// must match define in NaniteResources.h
#define MAX_VIEWS_PER_CULL_RASTERIZE_PASS_BITS	12														// must match define in NaniteResources.h
#define MAX_VIEWS_PER_CULL_RASTERIZE_PASS_MASK	( ( 1 << MAX_VIEWS_PER_CULL_RASTERIZE_PASS_BITS ) - 1 )	// must match define in NaniteResources.h
#define MAX_VIEWS_PER_CULL_RASTERIZE_PASS		( 1 << MAX_VIEWS_PER_CULL_RASTERIZE_PASS_BITS )			// must match define in NaniteResources.h
#define MAX_GPU_PAGES_BITS						13														// must match define in NaniteResources.h
#define	MAX_GPU_PAGES_MASK						( ( 1 << MAX_GPU_PAGES_BITS ) - 1 )						// must match define in NaniteResources.h
#define	MAX_GPU_PAGES							( 1 << MAX_GPU_PAGES_BITS )								// must match define in NaniteResources.h
#define MAX_INSTANCES_BITS						24														// must match define in NaniteResources.h
#define MAX_NODES_PER_PRIMITIVE_BITS			16														// must match define in NaniteResources.h
#define NUM_CULLING_FLAG_BITS					3														// must match define in NaniteResources.h
#define MAX_RESOURCE_PAGES_BITS					20														// must match define in NaniteResources.h
#define MAX_RESOURCE_PAGES						(1 << MAX_FILE_PAGES_BITS)								// must match define in NaniteResources.h
#define MAX_GROUP_PARTS_BITS					3														// must match define in NaniteResources.h
#define MAX_GROUP_PARTS							(1 << MAX_GROUP_PARTS)									// must match define in NaniteResources.h

#define MAX_TEXCOORD_QUANTIZATION_BITS			15														// must match define in NaniteResources.h
#define MAX_COLOR_QUANTIZATION_BITS				 8														// must match define in NaniteResources.h

#define NUM_STREAMING_PRIORITY_CATEGORY_BITS	 2														// must match define in NaniteResources.h
#define STREAMING_PRIORITY_CATEGORY_MASK		((1 << NUM_STREAMING_PRIORITY_CATEGORY_BITS) - 1)		// must match define in NaniteResources.h

#define VIEW_FLAG_HZBTEST						0x1														// must match define in NaniteResources.h

#define MAX_STATE_BUCKET_ID						((1 << 14) - 1)											// must match FNaniteCommandInfo::MAX_STATE_BUCKET_ID

#define CLUSTER_FLAG_LEAF						0x1

#define CULLING_FLAG_TEST_LOD					0x1
#define CULLING_FLAG_USE_HW						0x2
#define CULLING_FLAG_FROM_DISOCCLUDED_INSTANCE	0x4

#define MAX_TRANSCODE_GROUPS_PER_PAGE			128														// must match define in NaniteResources.h

#define NUM_PACKED_CLUSTER_FLOAT4S				8														// must match define in NaniteResources.h

#define POSITION_QUANTIZATION_BITS					10
#define NORMAL_QUANTIZATION_BITS					9

#define CULLING_PASS_NO_OCCLUSION					0
#define CULLING_PASS_OCCLUSION_MAIN					1
#define CULLING_PASS_OCCLUSION_POST					2
#define CULLING_PASS_EXPLICIT_LIST					3

#define RENDER_FLAG_HAVE_PREV_DRAW_DATA				0x1
#define RENDER_FLAG_FORCE_HW_RASTER					0x2
#define RENDER_FLAG_PRIMITIVE_SHADER				0x4
#define RENDER_FLAG_OUTPUT_STREAMING_REQUESTS		0x8

#define VERTEX_COLOR_MODE_WHITE						0
#define VERTEX_COLOR_MODE_CONSTANT					1
#define VERTEX_COLOR_MODE_VARIABLE					2

// Only available with the DEBUG_FLAGS permutation active.
#define DEBUG_FLAG_WRITE_STATS						0x1
#define DEBUG_FLAG_CULL_HZB_BOX						0x2
#define DEBUG_FLAG_CULL_HZB_SPHERE					0x4
#define DEBUG_FLAG_CULL_FRUSTUM_BOX					0x8
#define DEBUG_FLAG_CULL_FRUSTUM_SPHERE				0x10

#ifndef DEBUG_FLAGS
#define DEBUG_FLAGS 0
#endif

uint GetHWClusterCounterIndex(uint InRenderFlags)
{
// Ensure rasterizer uses compile time constants.
#ifdef NANITE_PRIM_SHADER
	#if NANITE_PRIM_SHADER
		return 4;
	#else
		return 5;
	#endif
#else
	// Other passes use a uniform branch to minimize permutations.
	return (InRenderFlags & RENDER_FLAG_PRIMITIVE_SHADER) ? 4 : 5;
#endif
}

// Debug Visualization Modes (must match NaniteRender.cpp)
// https://docs.google.com/document/d/1PeRxK_w49jgACYTiQUlCJYSzbT_BKZbhly_7i80j-BU/edit?usp=sharing
#define VISUALIZE_TRIANGLES							1
#define VISUALIZE_CLUSTERS							2
#define VISUALIZE_GROUPS							3
#define VISUALIZE_PAGES								4
#define VISUALIZE_PRIMITIVES						5
#define VISUALIZE_HW_VS_SW							6
#define VISUALIZE_OVERDRAW							7
#define VISUALIZE_HIERARCHY_OFFSET					8
#define VISUALIZE_SCN_HTILE_MINZ					9
#define VISUALIZE_SCN_HTILE_MAXZ					10
#define VISUALIZE_SCN_HTILE_DELTAZ					11
#define VISUALIZE_SCN_HTILE_ZMASK					12
#define VISUALIZE_MAT_HTILE_MINZ					13
#define VISUALIZE_MAT_HTILE_MAXZ					14
#define VISUALIZE_MAT_HTILE_DELTAZ					15
#define VISUALIZE_MAT_HTILE_ZMASK					16
#define VISUALIZE_MATERIAL_FAST_VS_SLOW				17
#define VISUALIZE_MATERIAL_INDEX					18
#define VISUALIZE_MATERIAL_ID						19
#define VISUALIZE_HIT_PROXY_ID						20
#define VISUALIZE_NANITE_MASK						21

struct FStats
{
	uint NumTris;
	uint NumVerts;
	uint NumViews;
	uint NumMainInstancesPreCull;
	uint NumMainInstancesPostCull;
	uint NumPostInstancesPreCull;
	uint NumPostInstancesPostCull;
	uint NumLargePageRectClusters;
};

struct FPersistentState
{
	uint	ReadOffset;
	uint	WriteOffset;
	int		NumActive;
};

struct FVisibleCluster
{
	uint	Flags;
	uint	ViewId;
	uint	InstanceId;
	uint	PageIndex;
	uint	ClusterIndex;
	uint2	vPage;
};

struct FVisibleNode
{
	uint	Flags;
	uint	ViewId;
	uint	InstanceId;
	uint	NodeIndex;
	uint	EnabledBitmask[2];
};

#define SIZEOF_UV_RANGE	32
struct FUVRange
{
	float2	Min;
	float2	Scale;
	uint2	GapStart;
	uint2	GapLength;
};

struct FTriCluster
{
	uint	PageBaseAddress;

	uint3	QuantizedPosStart;
	uint	PositionOffset;

	float3  MeshBoundsMin;
	uint	IndexOffset;

	float3	MeshBoundsDelta;
	uint	NumVerts;
	uint	NumTris;
	uint	BitsPerIndex;
	uint	QuantizedPosShift;

	float4	LODBounds;

	float3	BoxBoundsCenter;
	float	LODError;
	float	EdgeLength;

	float3	BoxBoundsExtent;
	uint	Flags;

	uint	AttributeOffset;
	uint	BitsPerAttribute;
	uint	DecodeInfoOffset;
	uint	NumUVs;
	uint	ColorMode;
	uint	UV_Prec;

	uint	ColorMin;
	uint	ColorBits;
	uint	GroupIndex;	// Debug only

	// Material Slow path
	uint	MaterialTableOffset;
	uint	MaterialTableLength;

	// Material Fast path
	uint	Material0Length;
	uint	Material0Index;
	uint 	Material1Length;
	uint	Material1Index;
	uint	Material2Index;
};

struct FHierarchyNodeSlice
{
	float4	Bounds;
	float4	LODBounds;
	float	MinLODError;
	float	MaxParentLODError;
	uint	ChildStartReference;	// Can be node (index) or cluster (page:cluster)
	uint	NumChildren;
	uint	StartPageIndex;
	uint	NumPages;
	bool	bEnabled;
	bool	bLoaded;
	bool	bLeaf;
};

struct FInstanceDynamicData
{
	float4x4	LocalToClip;
	float4x4	LocalToView;
	float4x4	ClipToLocal;
	float4x4 	PrevLocalToClip;
	float4x4	PrevLocalToView;
	float4x4	PrevClipToLocal;
	float3		ViewPosScaledLocal;
	float3		ViewForwardScaledLocal;
	bool		bHasMoved;
};

struct FNaniteView
{
	float4x4	TranslatedWorldToView;
	float4x4	TranslatedWorldToClip;
	float4x4	ViewToClip;
	float4x4	ClipToWorld;
	
	float4x4	PrevTranslatedWorldToView;
	float4x4	PrevTranslatedWorldToClip;
	float4x4	PrevViewToClip;
	float4x4	PrevClipToWorld;

	int4		ViewRect;
	float4		ViewSizeAndInvSize;
	float4		ClipSpaceScaleOffset;
	float3		PreViewTranslation;
	float3		PrevPreViewTranslation;
	float3		WorldCameraOrigin;
	float3		ViewForward;
	float		NearPlane;
	float		LODScale;
	float		LODScaleHW;
	float		MinBoundsRadiusSq;
	uint		StreamingPriorityCategory;
    uint		Flags;
	int			TargetLayerIndex;
	int			TargetMipLevel;
	int			TargetNumMipLevels;
	int			TargetPrevLayerIndex;
	int4		HZBTestViewRect;
};

struct FPackedNaniteView
{
	float4x4	TranslatedWorldToView;
	float4x4	TranslatedWorldToClip;
	float4x4	ViewToClip;
	float4x4	ClipToWorld;
	
	float4x4	PrevTranslatedWorldToView;
	float4x4	PrevTranslatedWorldToClip;
	float4x4	PrevViewToClip;
	float4x4	PrevClipToWorld;

	int4		ViewRect;
	float4		ViewSizeAndInvSize;
	float4		ClipSpaceScaleOffset;
	float4		PreViewTranslation;
	float4		PrevPreViewTranslation;
	float4		WorldCameraOrigin;
	float4		ViewForwardAndNearPlane;
	
	float2		LODScales;
	float		MinBoundsRadiusSq;
	uint		StreamingPriorityCategory_AndFlags;

	int4		TargetLayerIdX_AndMipLevelY_AndNumMipLevelsZ;

	int4		HZBTestViewRect;
};

struct FInstanceDraw
{
	uint InstanceId;
	uint ViewId;
};

#if NANITE_USE_UNIFORM_BUFFER
	#define SOAStrides 				Nanite.SOAStrides
	#define MaxNodes				Nanite.MaxNodes
	#define MaxClusters				Nanite.MaxClusters
	#define RenderFlags				Nanite.RenderFlags
	#define DebugFlags				Nanite.DebugFlags
	#define ClusterPageData			Nanite.ClusterPageData
	#define ClusterPageHeaders		Nanite.ClusterPageHeaders
	#define VisibleClustersSWHW		Nanite.VisibleClustersSWHW
#else
	uint4 							SOAStrides;
	uint							MaxNodes;
	uint							MaxClusters;
	uint							RenderFlags;
	uint							DebugFlags;
	ByteAddressBuffer 				ClusterPageData;
	ByteAddressBuffer 				ClusterPageHeaders;
	ByteAddressBuffer				VisibleClustersSWHW;
#endif

RWByteAddressBuffer					OutInstanceDynamicData;

// BitStreamReader
// Helper 'class' for efficiently parsing bit streams of arbitrary length.
#if 1
// Bit buffer implementation:
// Maintains an internal bit buffer instead of issuing memory loads at every read operation.
// Reads extract the bits from the bottom dword of the bit buffer. Whenever the bottom dword runs out of bits,
// it is refilled by shifting the bit buffer down (v_alignbit). Only when the bit buffer also runs out of bits
// is a memory load issued that then refills the buffer using a single load4.

// If the read sizes are divergent, it is very likely that for a given read at least one thread will need to refill, so
// in the worst case the refill has to happen at every read.
// To mitigate this, all reads have to supply a compile-time constant upper bound to the size of the read.
// By keeping track of these bounds, we can conservatively determine a which reads a refill can possibly be required and only
// emit the refill code in those instances.

// Everything prefixed with CompileTime should be compile-time constant and generate no code.
// We unfortunately have no way to enforce this.

struct FBitStreamReaderState
{
	ByteAddressBuffer InputBuffer;

	uint	AlignedByteAddress;
	int		BitOffsetFromAddress;

	uint4	BufferBits;
	int		BufferOffset;
	
	int		CompileTimeMinBufferBits;
	int		CompileTimeMinDwordBits;
	int		CompileTimeMaxRemainingBits;
};

FBitStreamReaderState BitStreamReader_Create_Aligned(ByteAddressBuffer InputBuffer, uint AlignedByteAddress, uint BitOffset, uint CompileTimeMaxRemainingBits)
{
	FBitStreamReaderState State;

	State.InputBuffer = InputBuffer;

	State.AlignedByteAddress = AlignedByteAddress;
	State.BitOffsetFromAddress = BitOffset;

	State.BufferBits = 0;
	State.BufferOffset = 0;

	State.CompileTimeMinBufferBits = 0;
	State.CompileTimeMinDwordBits = 0;
	State.CompileTimeMaxRemainingBits = CompileTimeMaxRemainingBits;

	return State;
}

FBitStreamReaderState BitStreamReader_Create(ByteAddressBuffer InputBuffer, uint ByteAddress, uint BitOffset, uint CompileTimeMaxRemainingBits)
{
	uint AlignedByteAddress = ByteAddress & ~3u;
	BitOffset += (ByteAddress & 3u) << 3;

	return BitStreamReader_Create_Aligned(InputBuffer, AlignedByteAddress, BitOffset, CompileTimeMaxRemainingBits);
}

uint BitStreamReader_Read(inout FBitStreamReaderState State, int NumBits, int CompileTimeMaxBits)
{
	if (CompileTimeMaxBits > State.CompileTimeMinBufferBits)
	{
		// BitBuffer could be out of bits: Reload.

		// Add cumulated offset since last refill. No need to update at every read.
		State.BitOffsetFromAddress += State.BufferOffset;	
		
		uint4 Data = State.InputBuffer.Load4(State.AlignedByteAddress + ((State.BitOffsetFromAddress >> 5) << 2));

		// Shift bits down to align
		State.BufferBits.x												= BitAlignU32(Data.y,	Data.x,	State.BitOffsetFromAddress);	// BitOffsetFromAddress implicitly &31
		if (State.CompileTimeMaxRemainingBits > 32) State.BufferBits.y	= BitAlignU32(Data.z,	Data.y,	State.BitOffsetFromAddress);	// BitOffsetFromAddress implicitly &31
		if (State.CompileTimeMaxRemainingBits > 64) State.BufferBits.z	= BitAlignU32(Data.w,	Data.z,	State.BitOffsetFromAddress);	// BitOffsetFromAddress implicitly &31
		if (State.CompileTimeMaxRemainingBits > 96) State.BufferBits.w	= BitAlignU32(0,		Data.w,	State.BitOffsetFromAddress);	// BitOffsetFromAddress implicitly &31

		State.BufferOffset = 0;

		State.CompileTimeMinDwordBits	= min(32, State.CompileTimeMaxRemainingBits);
		State.CompileTimeMinBufferBits	= min(97, State.CompileTimeMaxRemainingBits);	// Up to 31 bits wasted to alignment
	}
	else if (CompileTimeMaxBits > State.CompileTimeMinDwordBits)
	{
		// Bottom dword could be out of bits: Shift down.
		State.BitOffsetFromAddress += State.BufferOffset;

		State.BufferBits.x											= BitAlignU32(State.BufferBits.y,	State.BufferBits.x,	State.BufferOffset);	// BufferOffset implicitly &31
		if (State.CompileTimeMinBufferBits > 32) State.BufferBits.y	= BitAlignU32(State.BufferBits.z,	State.BufferBits.y,	State.BufferOffset);	// BufferOffset implicitly &31
		if (State.CompileTimeMinBufferBits > 64) State.BufferBits.z	= BitAlignU32(State.BufferBits.w,	State.BufferBits.z,	State.BufferOffset);	// BufferOffset implicitly &31
		if (State.CompileTimeMinBufferBits > 96) State.BufferBits.w	= BitAlignU32(0,					State.BufferBits.w, State.BufferOffset);	// BufferOffset implicitly &31

		State.BufferOffset = 0;

		State.CompileTimeMinDwordBits = min(32, State.CompileTimeMaxRemainingBits);
	}

	uint Result = BitFieldExtractU32(State.BufferBits.x, NumBits, State.BufferOffset);	// BufferOffset implicitly &31
	State.BufferOffset += NumBits;

	State.CompileTimeMinBufferBits	-= CompileTimeMaxBits;
	State.CompileTimeMinDwordBits		-= CompileTimeMaxBits;
	State.CompileTimeMaxRemainingBits	-= CompileTimeMaxBits;
	return Result;
}

uint2 BitStreamReader_Read2(inout FBitStreamReaderState State, int2 NumBits, int2 CompileTimeMaxBits)
{
	uint ResultX = BitStreamReader_Read(State, NumBits.x, CompileTimeMaxBits.x);
	uint ResultY = BitStreamReader_Read(State, NumBits.y, CompileTimeMaxBits.y);
	return uint2(ResultX, ResultY);
}

uint4 BitStreamReader_Read4(inout FBitStreamReaderState State, int4 NumBits, int4 CompileTimeMaxBits)
{
	uint ResultX = BitStreamReader_Read(State, NumBits.x, CompileTimeMaxBits.x);
	uint ResultY = BitStreamReader_Read(State, NumBits.y, CompileTimeMaxBits.y);
	uint ResultZ = BitStreamReader_Read(State, NumBits.z, CompileTimeMaxBits.z);
	uint ResultW = BitStreamReader_Read(State, NumBits.w, CompileTimeMaxBits.w);
	return uint4(ResultX, ResultY, ResultZ, ResultW);
}
#else
// Naive implementation
// Perform a memory read for every bit stream read.
struct FBitStreamReaderState
{
	ByteAddressBuffer InputBuffer;

	uint	AlignedByteAddress;
	int		BitOffset;
};

FBitStreamReaderState BitStreamReader_Create_Aligned(ByteAddressBuffer InputBuffer, uint AlignedByteAddress, uint BitOffset, uint CompileTimeMaxRemainingBits)
{
	FBitStreamReaderState State;

	State.InputBuffer = InputBuffer;

	State.AlignedByteAddress = AlignedByteAddress;
	State.BitOffset = BitOffset;

	return State;
}

FBitStreamReaderState BitStreamReader_Create(ByteAddressBuffer InputBuffer, uint ByteAddress, uint BitOffset, uint CompileTimeMaxRemainingBits)
{
	uint AlignedByteAddress = ByteAddress & ~3u;
	BitOffset += (ByteAddress & 3u) << 3;

	return BitStreamReader_Create_Aligned(InputBuffer, AlignedByteAddress, BitOffset, CompileTimeMaxRemainingBits);
}

uint BitStreamReader_Read(inout FBitStreamReaderState State, int NumBits, int CompileTimeMaxBits)
{
	uint2 Data = State.InputBuffer.Load2(State.AlignedByteAddress + ((State.BitOffset >> 5) << 2));
	uint AlignedData = BitAlignU32(Data.y, Data.x, State.BitOffset);
	State.BitOffset += NumBits;
	return BitFieldExtractU32(AlignedData, NumBits, 0);
}

uint2 BitStreamReader_Read2(inout FBitStreamReaderState State, int2 NumBits, int2 CompileTimeMaxBits)
{
	uint2 Data = State.InputBuffer.Load2(State.AlignedByteAddress + ((State.BitOffset >> 5) << 2));
	uint AlignedData = BitAlignU32(Data.y, Data.x, State.BitOffset);
	State.BitOffset += NumBits.x + NumBits.y;
	return uint2(BitFieldExtractU32(AlignedData, NumBits.x, 0), BitFieldExtractU32(AlignedData, NumBits.y, NumBits.x));
}

uint4 BitStreamReader_Read4(inout FBitStreamReaderState State, int4 NumBits, int4 CompileTimeMaxBits)
{
	uint2 Data = State.InputBuffer.Load2(State.AlignedByteAddress + ((State.BitOffset >> 5) << 2));
	uint AlignedData = BitAlignU32(Data.y, Data.x, State.BitOffset);
	State.BitOffset += NumBits.x + NumBits.y + NumBits.z + NumBits.w;

	uint4 Result;
	Result.x = BitFieldExtractU32(AlignedData, NumBits.x, 0);
	Result.y = BitFieldExtractU32(AlignedData, NumBits.y, NumBits.x);
	Result.z = BitFieldExtractU32(AlignedData, NumBits.z, NumBits.x + NumBits.y);
	Result.w = BitFieldExtractU32(AlignedData, NumBits.w, NumBits.x + NumBits.y + NumBits.z);
	return Result;
}
#endif

// Put bits to ByteAddressBuffer at bit offset. NumBits must be <= 31.
void PutBits(RWByteAddressBuffer Output, uint AlignedBaseAddress, uint BitOffset, uint Value, uint NumBits)
{
    uint BitOffsetInDword = (BitOffset & 31u);  // &31 is implicit in shifts
    
    uint Bits = Value << BitOffsetInDword;
    uint Address = AlignedBaseAddress + ((BitOffset >> 5) << 2);
    uint EndBitPos = BitOffsetInDword + NumBits;

    if(EndBitPos >= 32)
    {
        uint Mask = 0xFFFFFFFFu << (EndBitPos & 31u);
        Output.InterlockedAnd(Address + 4, Mask);
        Output.InterlockedOr(Address + 4, Value >> (32 - BitOffsetInDword));
    }

    {
        uint Mask = ~BitFieldMaskU32(NumBits, BitOffset);
        Output.InterlockedAnd(Address, Mask);
        Output.InterlockedOr(Address, Value << BitOffsetInDword);
    }
}

struct FBitStreamWriterState
{
	RWByteAddressBuffer  Output;
	uint AlignedByteAddress;
   	uint BufferBits;
    uint BufferOffset;
    uint BufferMask;
};

FBitStreamWriterState BitStreamWriter_Create_Aligned(RWByteAddressBuffer Output, uint AlignedBaseAddressInBytes, uint BitOffset)
{
	FBitStreamWriterState State;

	State.Output = Output;
	State.AlignedByteAddress = AlignedBaseAddressInBytes + ((BitOffset >> 5) << 2);
	BitOffset &= 31u;

	State.BufferBits = 0;
	State.BufferOffset = BitOffset;
	State.BufferMask = BitFieldMaskU32(BitOffset, 0);

	return State;
}


void BitStreamWriter_Writer(inout FBitStreamWriterState State, uint Value, int NumBits, int CompileTimeMaxBits)
{
    State.BufferBits |= Value << State.BufferOffset;

    uint NextBufferOffset = State.BufferOffset + NumBits;
    if(NextBufferOffset >= 32)
    {
        State.Output.InterlockedAnd(State.AlignedByteAddress, State.BufferMask);
        State.Output.InterlockedOr(State.AlignedByteAddress, State.BufferBits);
		State.BufferMask = 0;
        State.BufferBits = Value >> (32 - State.BufferOffset);
        State.AlignedByteAddress += 4;
    }
	State.BufferOffset = NextBufferOffset & 31;
}

void BitStreamWriter_Flush(inout FBitStreamWriterState State)
{
    if(State.BufferOffset > 0)
    {
        uint Mask = State.BufferMask | ~BitFieldMaskU32(State.BufferOffset, 0);
        State.Output.InterlockedAnd(State.AlignedByteAddress, Mask);
        State.Output.InterlockedOr(State.AlignedByteAddress, State.BufferBits);
    }
}

// Utility functions for packing bits into uints.
// When Position and NumBits can be determined at compile time this should be just as fast as manual bit packing.
// TODO: Verify on other compilers than wave.
uint ReadBits( uint4 Data, inout uint Position, uint NumBits )
{
	uint DwordIndex = Position >> 5;
	uint BitIndex = Position & 31;

	uint Value = Data[ DwordIndex ] >> BitIndex;
	if( BitIndex + NumBits > 32 )
		Value |= Data[ DwordIndex + 1 ] << ( 32 - BitIndex );

	Position += NumBits;

	uint Mask = ( ( 1u << NumBits ) - 1u );
	return Value & Mask;
}

void WriteBits( inout uint4 Data, inout uint Position, uint Value, uint NumBits )
{
	uint DwordIndex = Position >> 5;
	uint BitIndex = Position & 31;

	Data[ DwordIndex ] |= Value << BitIndex;
	if( BitIndex + NumBits > 32 )
		Data[ DwordIndex + 1 ] |= Value >> ( 32 - BitIndex );

	Position += NumBits;
}

FVisibleCluster GetVisibleCluster( ByteAddressBuffer VisibleClusters, uint ClusterIdx, bool bHasPageData = false )
{
	uint4 RawData;
	if( bHasPageData )
		RawData = uint4( VisibleClusters.Load3( ClusterIdx * 12 ), 0 );
	else
		RawData = uint4( VisibleClusters.Load2( ClusterIdx * 8 ), 0, 0 );

	uint BitPos = 0;

	FVisibleCluster VisibleCluster;
	VisibleCluster.Flags		= ReadBits( RawData, BitPos, NUM_CULLING_FLAG_BITS );
	VisibleCluster.ViewId		= ReadBits( RawData, BitPos, MAX_VIEWS_PER_CULL_RASTERIZE_PASS_BITS );
	VisibleCluster.InstanceId	= ReadBits( RawData, BitPos, MAX_INSTANCES_BITS );
	VisibleCluster.PageIndex	= ReadBits( RawData, BitPos, MAX_GPU_PAGES_BITS );
	VisibleCluster.ClusterIndex	= ReadBits( RawData, BitPos, MAX_CLUSTERS_PER_PAGE_BITS );
	if( bHasPageData )
	{
		VisibleCluster.vPage.x	= ReadBits( RawData, BitPos, 16 );
		VisibleCluster.vPage.y	= ReadBits( RawData, BitPos, 16 );
	}
	else
	{
		VisibleCluster.vPage = 0;
	}

	return VisibleCluster;
}

FVisibleCluster GetVisibleCluster( uint ClusterIdx, bool bHasPageData )
{
	return GetVisibleCluster( VisibleClustersSWHW, ClusterIdx, bHasPageData );
}

FVisibleCluster GetVisibleCluster( uint ClusterIndex )
{
	FVisibleCluster VisibleCluster;

	bool bImposter = ClusterIndex >= (1 << 24);
	if( bImposter )
	{
		// Couldn't have been stored so signals this is an imposter
		VisibleCluster.Flags = 1 << NUM_CULLING_FLAG_BITS;
		VisibleCluster.ViewId = 0;	// TODO
		VisibleCluster.InstanceId = BitFieldExtractU32( ClusterIndex, MAX_INSTANCES_BITS - 1, 1 );
		VisibleCluster.PageIndex = 0;
		VisibleCluster.ClusterIndex = ClusterIndex & 1;
	}
	else
	{
		VisibleCluster = GetVisibleCluster( ClusterIndex, false );
	}

	return VisibleCluster;
}

FInstanceSceneData GetInstanceData( inout FVisibleCluster VisibleCluster )
{
	FInstanceSceneData InstanceData = GetInstanceData( VisibleCluster.InstanceId, SOAStrides.x );

	// Couldn't have been stored so signals this is an imposter
	if( VisibleCluster.Flags == (1 << NUM_CULLING_FLAG_BITS) )
	{
		const uint MaxStreamingPages = 1 << 12;
		VisibleCluster.PageIndex = MaxStreamingPages + (InstanceData.NaniteRuntimeResourceID & MAX_GPU_PAGES_MASK);
	}

	return InstanceData;
}

void StoreVisibleCluster( RWByteAddressBuffer VisibleClusters, uint ClusterIdx, FVisibleCluster VisibleCluster, bool bHasPageData = false )
{
	uint4 RawData = 0;
	uint BitPos = 0;
	WriteBits( RawData, BitPos, VisibleCluster.Flags,		NUM_CULLING_FLAG_BITS );
	WriteBits( RawData, BitPos, VisibleCluster.ViewId,		MAX_VIEWS_PER_CULL_RASTERIZE_PASS_BITS );
	WriteBits( RawData, BitPos, VisibleCluster.InstanceId,	MAX_INSTANCES_BITS );
	WriteBits( RawData, BitPos, VisibleCluster.PageIndex,	MAX_GPU_PAGES_BITS );
	WriteBits( RawData, BitPos, VisibleCluster.ClusterIndex,MAX_CLUSTERS_PER_PAGE_BITS );
	if( bHasPageData )
	{
		WriteBits( RawData, BitPos, VisibleCluster.vPage.x,	16 );
		WriteBits( RawData, BitPos, VisibleCluster.vPage.y,	16 );
		VisibleClusters.Store3( ClusterIdx * 12, RawData.xyz );
	}
	else
	{
		VisibleClusters.Store2( ClusterIdx * 8, RawData.xy );
	}
}

FVisibleNode GetVisibleNode( RWCoherentByteAddressBuffer VisibleNodes, uint NodeIdx, bool bHasEnabledMask )
{
	uint4 RawData = bHasEnabledMask ? VisibleNodes.Load4( NodeIdx * 16 ) : uint4( VisibleNodes.Load2( NodeIdx * 8 ), 0, 0 );
	uint BitPos = 0;

	FVisibleNode Node;
	Node.Flags		= ReadBits( RawData, BitPos, NUM_CULLING_FLAG_BITS );
	Node.InstanceId	= ReadBits( RawData, BitPos, MAX_INSTANCES_BITS );
	Node.NodeIndex	= ReadBits( RawData, BitPos, MAX_NODES_PER_PRIMITIVE_BITS );
	Node.ViewId		= ReadBits( RawData, BitPos, MAX_VIEWS_PER_CULL_RASTERIZE_PASS_BITS );
	if( bHasEnabledMask )
	{
		Node.EnabledBitmask[ 0 ] = RawData.z;
		Node.EnabledBitmask[ 1 ] = RawData.w;
	}
	else
	{
		Node.EnabledBitmask[ 0 ] = 0xFFFFFFFFu;
		Node.EnabledBitmask[ 1 ] = 0xFFFFFFFFu;
	}
	
	return Node;
}

bool IsVisibleNodeReady( RWCoherentByteAddressBuffer VisibleNodes, uint NodeIdx, bool bHasEnabledMask )
{
	const uint Stride = bHasEnabledMask ? 16 : 8;
	return VisibleNodes.Load( NodeIdx * Stride ) != 0xFFFFFFFF;
}

void MarkVisibleNodeAsClear( RWCoherentByteAddressBuffer VisibleNodes, uint NodeIdx, bool bHasEnabledMask )
{
	const uint Stride = bHasEnabledMask ? 16 : 8;
	VisibleNodes.Store( NodeIdx * Stride, 0xFFFFFFFF );
}

uint4 PackVisibleNode( FVisibleNode Node )
{
	uint4 RawData = 0;
	uint BitPos = 0;
	WriteBits( RawData, BitPos, Node.Flags,			NUM_CULLING_FLAG_BITS );
	WriteBits( RawData, BitPos, Node.InstanceId,	MAX_INSTANCES_BITS );
	WriteBits( RawData, BitPos, Node.NodeIndex,		MAX_NODES_PER_PRIMITIVE_BITS );
	WriteBits( RawData, BitPos, Node.ViewId,		MAX_VIEWS_PER_CULL_RASTERIZE_PASS_BITS );
	RawData.z = Node.EnabledBitmask[ 0 ];
	RawData.w = Node.EnabledBitmask[ 1 ];
	return RawData;
}

void StoreVisibleNodeSync( RWCoherentByteAddressBuffer VisibleNodes, uint NodeIdx, FVisibleNode VisibleNode, bool bHasEnabledMask )
{
	const uint Stride = bHasEnabledMask ? 16 : 8;
	uint4 RawData = PackVisibleNode( VisibleNode );
	
	if(bHasEnabledMask)
		VisibleNodes.Store3( NodeIdx * Stride + 4, RawData.yzw );
	else
		VisibleNodes.Store( NodeIdx * Stride + 4, RawData.y );

	DeviceMemoryBarrier();
	VisibleNodes.Store( NodeIdx * Stride, RawData.x );
}

void StoreVisibleNode( RWByteAddressBuffer VisibleNodes, uint NodeIdx, FVisibleNode VisibleNode, bool bHasEnabledMask )
{
	uint4 RawData = PackVisibleNode( VisibleNode );
	if(bHasEnabledMask)
		VisibleNodes.Store4( NodeIdx * 16, RawData );
	else
		VisibleNodes.Store2( NodeIdx * 8, RawData.xy );
}

FInstanceDynamicData CalculateInstanceDynamicData( FNaniteView NaniteView, FInstanceSceneData InstanceData )
{
	float4x4 LocalToWorld = InstanceData.LocalToWorld;
	float4x4 WorldToLocal = InstanceData.WorldToLocal;

	float4x4 LocalToTranslatedWorld = LocalToWorld;
	LocalToTranslatedWorld[3].xyz += NaniteView.PreViewTranslation.xyz;

	float4x4 PrevLocalToTranslatedWorld = InstanceData.PrevLocalToWorld;
	PrevLocalToTranslatedWorld[3].xyz += NaniteView.PrevPreViewTranslation.xyz;

	FInstanceDynamicData DynamicData;
	DynamicData.LocalToView = mul( LocalToTranslatedWorld, NaniteView.TranslatedWorldToView );
	DynamicData.LocalToClip = mul( LocalToTranslatedWorld, NaniteView.TranslatedWorldToClip );
	DynamicData.ClipToLocal = mul( NaniteView.ClipToWorld, WorldToLocal );

	DynamicData.PrevLocalToView	= mul( PrevLocalToTranslatedWorld, NaniteView.PrevTranslatedWorldToView );
	DynamicData.PrevLocalToClip	= mul( PrevLocalToTranslatedWorld, NaniteView.PrevTranslatedWorldToClip );
	DynamicData.PrevClipToLocal	= mul( NaniteView.PrevClipToWorld, WorldToLocal );

	DynamicData.ViewPosScaledLocal = mul( float4( NaniteView.WorldCameraOrigin.xyz, 1 ), WorldToLocal ).xyz * InstanceData.NonUniformScale.xyz;
	DynamicData.ViewForwardScaledLocal = mul( float4( NaniteView.ViewForward.xyz, 0 ), WorldToLocal ).xyz * InstanceData.NonUniformScale.xyz;

	DynamicData.bHasMoved = GetGPUSceneFrameNumber() == InstanceData.LastUpdateSceneFrameNumber;

	return DynamicData;
}

FInstanceSceneData GetInstanceData( uint InstanceId )
{
	return GetInstanceData( InstanceId, SOAStrides.x );
}

FTriCluster GetCluster(ByteAddressBuffer InputBuffer, uint SrcBaseOffset, uint ClusterIndex, uint NumPageClusters)
{
	uint ClusterSOAStride = ( NumPageClusters << 4 );

	uint ClusterBaseAddress = SrcBaseOffset + ( ClusterIndex << 4 );
	
	uint4 ClusterData[8];
	ClusterData[0] = InputBuffer.Load4( ClusterBaseAddress + 0 * ClusterSOAStride );
	ClusterData[1] = InputBuffer.Load4( ClusterBaseAddress + 1 * ClusterSOAStride );
	ClusterData[2] = InputBuffer.Load4( ClusterBaseAddress + 2 * ClusterSOAStride );
	ClusterData[3] = InputBuffer.Load4( ClusterBaseAddress + 3 * ClusterSOAStride );
	ClusterData[4] = InputBuffer.Load4( ClusterBaseAddress + 4 * ClusterSOAStride );
	ClusterData[5] = InputBuffer.Load4( ClusterBaseAddress + 5 * ClusterSOAStride );
	ClusterData[6] = InputBuffer.Load4( ClusterBaseAddress + 6 * ClusterSOAStride );
	ClusterData[7] = InputBuffer.Load4( ClusterBaseAddress + 7 * ClusterSOAStride );

	FTriCluster Cluster;
	Cluster.PageBaseAddress		= 0;

	Cluster.QuantizedPosStart	= ClusterData[0].xyz;
	Cluster.PositionOffset		= ClusterData[0].w;

	Cluster.MeshBoundsMin		= asfloat( ClusterData[1].xyz );
	Cluster.IndexOffset			= ClusterData[1].w;

	Cluster.MeshBoundsDelta		= asfloat( ClusterData[2].xyz );
	Cluster.NumVerts			= BitFieldExtractU32(ClusterData[2].w, 9, 0);
	Cluster.NumTris				= BitFieldExtractU32(ClusterData[2].w, 8, 9);
	Cluster.BitsPerIndex		= BitFieldExtractU32(ClusterData[2].w, 4, 9+8);
	Cluster.QuantizedPosShift	= BitFieldExtractU32(ClusterData[2].w, 6, 9+8+4);

	Cluster.LODBounds			= asfloat(ClusterData[3]);

	Cluster.BoxBoundsCenter		= asfloat(ClusterData[4].xyz);
	Cluster.LODError			= f16tof32(ClusterData[4].w);
	Cluster.EdgeLength			= f16tof32(ClusterData[4].w >> 16);

	Cluster.BoxBoundsExtent		= asfloat(ClusterData[5].xyz);
	Cluster.Flags				= ClusterData[5].w;


	Cluster.AttributeOffset		= BitFieldExtractU32(ClusterData[6].x, 22,  0);
	Cluster.BitsPerAttribute	= BitFieldExtractU32(ClusterData[6].x, 10, 22);
	Cluster.DecodeInfoOffset	= BitFieldExtractU32(ClusterData[6].y, 22,  0);
	Cluster.NumUVs				= BitFieldExtractU32(ClusterData[6].y,  3, 22);
	Cluster.ColorMode			= BitFieldExtractU32(ClusterData[6].y,  2, 22+3);
	Cluster.UV_Prec				= ClusterData[6].z;
	const uint MaterialEncoding = ClusterData[6].w;

	Cluster.ColorMin			= ClusterData[7].x;
	Cluster.ColorBits			= ClusterData[7].y;
	Cluster.GroupIndex			= ClusterData[7].z;			// Debug only

	// Material Table Range Encoding (32 bits)
	// uint TriStart        :  8;  // max 128 triangles
	// uint TriLength       :  8;  // max 128 triangles
	// uint MaterialIndex   :  6;  // max  64 materials
	// uint Padding         : 10;

	// Material Packed Range - Fast Path (32 bits)
	// uint Material0Length : 7;  // max 128 triangles (num minus one)
	// uint Material0Index  : 6;  // max  64 materials (0:Material0Length)
	// uint Material1Length : 7;  // max 128 triangles (num minus one)
	// uint Material1Index  : 6;  // max  64 materials (Material0Length:Material1Length)
	// uint Material2Index  : 6;  // max  64 materials (remainder)

	// Material Packed Range - Slow Path (32 bits)
	// uint Padding         : 7;  // always 0 in slow path
	// uint BufferIndex     : 19; // 2^19 max value (tons, it's per prim)
	// uint BufferLength    : 6;  // max 127 ranges (num)

	Cluster.Material0Length = MaterialEncoding & 0x0000007F;
	if (Cluster.Material0Length > 0)
	{
		// Fast inline path
		Cluster.MaterialTableOffset	= 0;
		Cluster.MaterialTableLength	= 0;
		Cluster.Material0Index		= (MaterialEncoding & 0x00001F80) >> 7;
		Cluster.Material1Length		= (MaterialEncoding & 0x000FE000) >> 13;
		Cluster.Material1Index		= (MaterialEncoding & 0x03F00000) >> 20;
		Cluster.Material2Index		= (MaterialEncoding & 0xFC000000) >> 26;

		Cluster.Material0Length++;
		if (Cluster.Material0Length < 128)
		{
			Cluster.Material1Length++;
		}
	}
	else
	{
		// Slow global search path
		Cluster.MaterialTableOffset	= (MaterialEncoding & 0x03FFFF80) >> 7;
		Cluster.MaterialTableLength	= (MaterialEncoding & 0xFC000000) >> 26;
		Cluster.Material0Length		= 0;
		Cluster.Material0Index		= 0;
		Cluster.Material1Length		= 0;
		Cluster.Material1Index		= 0;
		Cluster.Material2Index		= 0;
	}

	return Cluster;
}

FTriCluster GetCluster(uint PageIndex, uint ClusterIndex)
{
	uint NumClusters = ClusterPageHeaders.Load(PageIndex * 4);
	uint PageBaseAddress = (PageIndex << CLUSTER_PAGE_GPU_SIZE_BITS);
	
	FTriCluster Cluster = GetCluster(ClusterPageData, PageBaseAddress, ClusterIndex, NumClusters);
	Cluster.PageBaseAddress = PageBaseAddress;
	return Cluster;
}

FUVRange GetUVRange(ByteAddressBuffer InputBuffer, uint StartOffset, uint Index)
{
	uint Offset = StartOffset + Index * SIZEOF_UV_RANGE;
	uint4 Data[2];
	Data[0] = InputBuffer.Load4(Offset);
	Data[1] = InputBuffer.Load4(Offset + 16);

	FUVRange Range;
	Range.Min =			asfloat(Data[0].xy);
	Range.Scale =		asfloat(Data[0].zw);
	Range.GapStart =	Data[1].xy;
	Range.GapLength =	Data[1].zw;
	return Range;
}

// Decode triangle that is represented by one base index and two 5-bit offsets.
uint3 ReadTriangleIndices(FTriCluster Cluster, uint TriIndex)
{
	const uint BitsPerTriangle = Cluster.BitsPerIndex + 2 * 5;

	FBitStreamReaderState BitStreamReader = BitStreamReader_Create_Aligned(ClusterPageData, Cluster.PageBaseAddress + Cluster.IndexOffset, TriIndex * BitsPerTriangle, 8 + 2*5);

	uint BaseIndex = BitStreamReader_Read(BitStreamReader, Cluster.BitsPerIndex, 8);
	uint Delta0 = BitStreamReader_Read(BitStreamReader, 5, 5);
	uint Delta1 = BitStreamReader_Read(BitStreamReader, 5, 5);

	return BaseIndex + uint3(0, Delta0, Delta1);
}

uint3 UnpackToUint3(uint Value, int3 NumComponentBits)
{
	return uint3(	BitFieldExtractU32(Value, NumComponentBits.x, 0),
					BitFieldExtractU32(Value, NumComponentBits.y, NumComponentBits.x),
					BitFieldExtractU32(Value, NumComponentBits.z, NumComponentBits.x + NumComponentBits.y));
}

uint4 UnpackToUint4(uint Value, int4 NumComponentBits)
{
	return uint4(	BitFieldExtractU32(Value, NumComponentBits.x, 0),
					BitFieldExtractU32(Value, NumComponentBits.y, NumComponentBits.x),
					BitFieldExtractU32(Value, NumComponentBits.z, NumComponentBits.x + NumComponentBits.y),
					BitFieldExtractU32(Value, NumComponentBits.w, NumComponentBits.x + NumComponentBits.y + NumComponentBits.z));
}

// TODO: Move to a proper common location
uint FloatToUIntScaled(float Value, float Scale)
{
	return (uint)floor(Value * Scale + 0.5f);
}

// TODO: Move to a proper common location
uint Pack_Float4_To_R10G10B10A2_UNORM(float4 Unpacked)
{
	const float4 UnpackedClamped = saturate(Unpacked);
	uint Packed = ((FloatToUIntScaled(UnpackedClamped.x, 1023))       |
				   (FloatToUIntScaled(UnpackedClamped.y, 1023) << 10) |
				   (FloatToUIntScaled(UnpackedClamped.z, 1023) << 20) |
				   (FloatToUIntScaled(UnpackedClamped.w,    3) << 30) );
	return Packed;
}

// TODO: Move to a proper common location
float4 Unpack_R10G10B10A2_UNORM_To_Float4(uint Packed)
{
	float4 Unpacked;
	Unpacked.x = (float)(((Packed      ) & 0x000003FF)) / 1023;
	Unpacked.y = (float)(((Packed >> 10) & 0x000003FF)) / 1023;
	Unpacked.z = (float)(((Packed >> 20) & 0x000003FF)) / 1023;
	Unpacked.w = (float)(((Packed >> 30) & 0x00000003)) / 3;
	return Unpacked;
}

void UnpackVisPixel(
	UlongType Pixel,
	out uint DepthInt,
	out uint VisibleClusterIndex, 
	out uint TriIndex
	)
{
	const uint2 Unpacked = UnpackUlongType(Pixel);
	VisibleClusterIndex = Unpacked.x >> 7;
	TriIndex = Unpacked.x & 0x7F;
	DepthInt = Unpacked.y;

	VisibleClusterIndex--;
}

void UnpackDbgPixel(
	UlongType Pixel,
	out uint DepthInt,
	out uint DebugValue
	)
{
	const uint2 Unpacked = UnpackUlongType(Pixel);
	DebugValue = Unpacked.x;
	DepthInt = Unpacked.y;
}

float3 UnpackPosition(uint Packed, FTriCluster Cluster, uint Bits)
{
	return (uint3(BitFieldExtractU32(Packed, Bits, 0), BitFieldExtractU32(Packed, Bits, Bits), BitFieldExtractU32(Packed, Bits, 2*Bits)) + Cluster.QuantizedPosStart) * Cluster.MeshBoundsDelta + Cluster.MeshBoundsMin;
}

float2 UnpackTexCoord(uint2 Packed, FUVRange UVRange)
{
	uint2 T = Packed + ((Packed >= UVRange.GapStart) ? UVRange.GapLength : 0u);
	return float2(T) * UVRange.Scale + UVRange.Min;
}

float3 UnpackNormal(uint Packed, uint Bits)
{
	uint Mask = BitFieldMaskU32(Bits, 0);
	float2 F = uint2(BitFieldExtractU32(Packed, Bits, 0), BitFieldExtractU32(Packed, Bits, Bits)) * (2.0f / Mask) - 1.0f;
	float3 N = float3(F.xy, 1.0 - abs(F.x) - abs(F.y));
	float T = saturate(-N.z);
	N.xy += N.xy >= 0.0 ? -T : T;
	return N;
}

bool IsMaterialFastPath(FTriCluster InCluster)
{
	return (InCluster.Material0Length > 0);
}

uint GetRelativeMaterialIndex(FTriCluster InCluster, uint InTriIndex)
{
	uint MaterialIndex = 0xFFFFFFFF;

	BRANCH
	if (IsMaterialFastPath(InCluster))
	{
		if (InTriIndex < InCluster.Material0Length)
		{
			MaterialIndex = InCluster.Material0Index;
		}
		else if (InTriIndex < (InCluster.Material0Length + InCluster.Material1Length))
		{
			MaterialIndex = InCluster.Material1Index;
		}
		else
		{
			MaterialIndex = InCluster.Material2Index;
		}
	}
	else
	{
		uint TableOffset = InCluster.PageBaseAddress + InCluster.MaterialTableOffset * 4;
		for (uint TableEntry = 0; TableEntry < InCluster.MaterialTableLength; ++TableEntry)
		{
			uint EncodedRange = ClusterPageData.Load(TableOffset);
			TableOffset += 4;

			// uint32 TriStart      :  8; // max 128 triangles
			// uint32 TriLength     :  8; // max 128 triangles
			// uint32 MaterialIndex :  6; // max  64 materials
			// uint32 Padding       : 10;

			const uint TriStart = (EncodedRange & 0x000000FF);
			const uint TriLength = (EncodedRange & 0x0000FF00) >> 8;
			if (InTriIndex >= TriStart && InTriIndex < (TriStart + TriLength))
			{
				MaterialIndex = (EncodedRange & 0x003F0000) >> 16;
				break;
			}
		}
	}

	return MaterialIndex;
}

uint RemapMaterialIndexToId(uint InPrimitiveIndex, uint InMaterialIndex, ByteAddressBuffer InMaterialTable)
{
	// Remap local primitive material indices (i.e. 0...8) to global indices of all primitives in current scene
	const uint MaxMaterials = 64;
	const uint RemapOffset = (InPrimitiveIndex * MaxMaterials * 4) + (InMaterialIndex * 4);
	const uint MaterialId = InMaterialTable.Load(RemapOffset);
	return MaterialId;
}

uint GetMaterialDepthId(
	FTriCluster InCluster,
	uint InPrimitiveIndex,
	uint InTriIndex,
	ByteAddressBuffer InMaterialDepthTable)
{
	const uint RelativeMaterialIndex = GetRelativeMaterialIndex(InCluster, InTriIndex);
	const uint MaterialDepthId = RemapMaterialIndexToId(InPrimitiveIndex, RelativeMaterialIndex, InMaterialDepthTable);
	return MaterialDepthId;
}

uint GetMaterialHitProxyId(
	FTriCluster InCluster,
	uint InPrimitiveIndex,
	uint InTriIndex,
	ByteAddressBuffer InMaterialHitProxyTable)
{
	const uint RelativeMaterialIndex = GetRelativeMaterialIndex(InCluster, InTriIndex);
	const uint MaterialHitProxyId = RemapMaterialIndexToId(InPrimitiveIndex, RelativeMaterialIndex, InMaterialHitProxyTable);
	return MaterialHitProxyId;
}

uint GetMaterialBucketIdFromDepth(float Depth)
{
	return (uint)(Depth * MAX_STATE_BUCKET_ID);
}

StructuredBuffer< FPackedNaniteView > InViews;
FNaniteView GetNaniteView( uint ViewIndex )
{
#if NANITE_USE_VIEW_UNIFORM_BUFFER
	FNaniteView NaniteView;

	NaniteView.TranslatedWorldToView		= View.TranslatedWorldToView;
	NaniteView.TranslatedWorldToClip		= View.TranslatedWorldToClip;
	NaniteView.ViewToClip					= View.ViewToClip;
	NaniteView.ClipToWorld					= View.ClipToWorld;
	
	NaniteView.PrevTranslatedWorldToView	= View.PrevTranslatedWorldToView;
	NaniteView.PrevTranslatedWorldToClip	= View.PrevTranslatedWorldToClip;
	NaniteView.PrevViewToClip				= View.PrevViewToClip;
	NaniteView.PrevClipToWorld				= View.PrevInvViewProj;

	NaniteView.ViewSizeAndInvSize			= View.ViewSizeAndInvSize;
	NaniteView.ViewRect						= int4(int2(View.ViewRectMin.xy + 0.5f), int2(View.ViewRectMin.xy + View.ViewSizeAndInvSize.zy + 0.5f));
	NaniteView.PreViewTranslation			= View.PreViewTranslation;
	NaniteView.PrevPreViewTranslation		= View.PrevPreViewTranslation;
	NaniteView.WorldCameraOrigin			= View.WorldCameraOrigin;
	NaniteView.ViewForward					= View.ViewForward;
	NaniteView.NearPlane					= View.NearPlane;
	NaniteView.LODScale						= 1.0f;
	NaniteView.LODScaleHW					= 1.0f;
	NaniteView.MinBoundsRadiusSq			= 0;
	NaniteView.StreamingPriorityCategory	= 3;
	NaniteView.Flags						= VIEW_FLAG_HZBTEST;
	
	NaniteView.TargetLayerIndex				= 0;
	NaniteView.TargetMipLevel				= 0;
	NaniteView.TargetNumMipLevels			= 0;
	NaniteView.TargetPrevLayerIndex			= 0;

	NaniteView.HZBTestViewRect				= NaniteView.ViewRect;

#else // !NANITE_USE_VIEW_UNIFORM_BUFFER

#if NANITE_MULTI_VIEW
	FPackedNaniteView PackedView = InViews[ViewIndex];
#else
	FPackedNaniteView PackedView = InViews[0];
#endif

	FNaniteView NaniteView;

	NaniteView.TranslatedWorldToView		= PackedView.TranslatedWorldToView;
	NaniteView.TranslatedWorldToClip		= PackedView.TranslatedWorldToClip;
	NaniteView.ViewToClip					= PackedView.ViewToClip;
	NaniteView.ClipToWorld					= PackedView.ClipToWorld;
	
	NaniteView.PrevTranslatedWorldToView	= PackedView.PrevTranslatedWorldToView;
	NaniteView.PrevTranslatedWorldToClip	= PackedView.PrevTranslatedWorldToClip;
	NaniteView.PrevViewToClip				= PackedView.PrevViewToClip;
	NaniteView.PrevClipToWorld				= PackedView.PrevClipToWorld;

	NaniteView.ViewRect						= PackedView.ViewRect;
	NaniteView.ViewSizeAndInvSize			= PackedView.ViewSizeAndInvSize;
	NaniteView.ClipSpaceScaleOffset			= PackedView.ClipSpaceScaleOffset;
	NaniteView.PreViewTranslation			= PackedView.PreViewTranslation.xyz;
	NaniteView.PrevPreViewTranslation		= PackedView.PrevPreViewTranslation.xyz;
	NaniteView.WorldCameraOrigin			= PackedView.WorldCameraOrigin.xyz;
	NaniteView.ViewForward					= PackedView.ViewForwardAndNearPlane.xyz;
	NaniteView.NearPlane					= PackedView.ViewForwardAndNearPlane.w;
	NaniteView.LODScale						= PackedView.LODScales.x;
	NaniteView.LODScaleHW					= PackedView.LODScales.y;
	NaniteView.MinBoundsRadiusSq			= PackedView.MinBoundsRadiusSq;
	NaniteView.StreamingPriorityCategory	= PackedView.StreamingPriorityCategory_AndFlags & STREAMING_PRIORITY_CATEGORY_MASK;
	NaniteView.Flags						= PackedView.StreamingPriorityCategory_AndFlags >> NUM_STREAMING_PRIORITY_CATEGORY_BITS;
	
	NaniteView.TargetLayerIndex				= PackedView.TargetLayerIdX_AndMipLevelY_AndNumMipLevelsZ.x;
	NaniteView.TargetMipLevel				= PackedView.TargetLayerIdX_AndMipLevelY_AndNumMipLevelsZ.y;
	NaniteView.TargetNumMipLevels			= PackedView.TargetLayerIdX_AndMipLevelY_AndNumMipLevelsZ.z;
	NaniteView.TargetPrevLayerIndex			= PackedView.TargetLayerIdX_AndMipLevelY_AndNumMipLevelsZ.w;

	NaniteView.HZBTestViewRect				= PackedView.HZBTestViewRect;

#endif // NANITE_USE_VIEW_UNIFORM_BUFFER

	return NaniteView;
}
