// Copyright Epic Games, Inc. All Rights Reserved.

/*=============================================================================
	PageManagement.usf: 
=============================================================================*/

#include "../Common.ush"
#include "../LightGridCommon.ush"
#include "../SceneTexturesCommon.ush"
#include "../DeferredShadingCommon.ush"
#include "../MortonCode.ush"
#include "../Nanite/NaniteDataDecode.ush"
#include "PageAccessCommon.ush"
#include "ProjectionCommon.ush"

#ifndef VSM_GENERATE_STATS
	#define VSM_GENERATE_STATS 0
#endif // VSM_GENERATE_STATS

#if VSM_GENERATE_STATS
RWStructuredBuffer<uint> OutStatsBuffer;
#endif // VSM_GENERATE_STATS

// Counter used to allocate physical pages from a linear range, which is mapped to a Physical 2D texture (by wrapping)
RWStructuredBuffer<uint> AllocatedPagesOffset;
// Flags generated by per-pixel pass to determine which pages are required to provide shadow for the visible geometry
RWStructuredBuffer<uint> OutPageRequestFlags;
RWStructuredBuffer<uint2> OutPageTable;

// Page flags generated by page allocation to indicate state to rendering passes (i.e., present / invalid)
RWStructuredBuffer<uint> OutPageFlags;

// Stores a uint2 with the physical location of cached pages in the previous frame physical texture, newly allocated ones are set to invalid index
RWStructuredBuffer<FCachedPageInfo> OutCachedPageInfos;

void CreatePageMapping( uint ShadowMapID, uint MipLevel, uint2 PageAddress, uint PageOffset, bool bPageRequestFlag )
{	
	if( bPageRequestFlag )
	{
		uint pPageIndex = 0;
		InterlockedAdd( AllocatedPagesOffset[0], 1, pPageIndex );

#if VSM_GENERATE_STATS
		InterlockedAdd(OutStatsBuffer[0], 1);
#endif // VSM_GENERATE_STATS

		if (pPageIndex >= MaxPhysicalPages)
		{
			// We end up here if we're out of physical pages, this means some parts get no physical backing provided.
			// Post this error condition back to the host somehow!
			// Probably want to know if we're getting close even.
			OutPageTable[PageOffset] = VSM_INVALID_PHYSICAL_PAGE_ADDRESS;
			OutPageFlags[PageOffset] = 0;
			return;
		}


		// Wrap linear page index into physical 2D space
		uint2 pPage;
		pPage.x = pPageIndex  & PhysicalPageRowMask;
		pPage.y = pPageIndex >> PhysicalPageRowShift;

		OutPageTable[ PageOffset ] = pPage;

		FCachedPageInfo CachedPageInfo;

		CachedPageInfo.PhysPageAddress = uint2(VSM_INVALID_PHYSICAL_PAGE_ADDRESS, VSM_INVALID_PHYSICAL_PAGE_ADDRESS);
		CachedPageInfo.DepthOffset = 0.0f;
		CachedPageInfo.Padding = 0.0f;

#if HAS_CACHE_DATA
		if (ShadowMapCacheData[ShadowMapID].VirtualShadowMapId != INDEX_NONE)
		{
			CachedPageInfo.DepthOffset = ShadowMapCacheData[ShadowMapID].DepthOffset;

			int2 PrevPageAddress = int2(PageAddress) - (ShadowMapCacheData[ShadowMapID].SmPageOffset >> MipLevel);
			// A page cannot be cached if it is above the alignment level, or the light has not moved
			// This means that for small movement a CSM can cache everything as well.
			bool bCanCache = MipLevel < VSM_CACHE_ALIGNMENT_LEVEL || all(ShadowMapCacheData[ShadowMapID].SmPageOffset == 0);
			if (all(uint2(PrevPageAddress) < CalcLevelDimsPages(MipLevel)) && bCanCache)
			{
				uint PrevOffset = CalcPageOffset(ShadowMapCacheData[ShadowMapID].VirtualShadowMapId, MipLevel, PrevPageAddress);
				uint PrevPageFlag = PrevPageFlags[PrevOffset];
				// True if the page had moving stuff drawn into it
				bool PrevDynPageFlag = PrevDynamicCasterPageFlags[PrevOffset] != 0;

#if VSM_GENERATE_STATS
				// stats for those pages who die from moving stuff
				if (PrevPageFlag && PrevDynPageFlag)
				{
					InterlockedAdd(OutStatsBuffer[2], 1);
				}
#endif // VSM_GENERATE_STATS
				// If it was either rendered or cached previous frame, and not drawn to by a moving thing we may re-use
				if (PrevPageFlag && !PrevDynPageFlag)
				{
					uint2 PrevPhysAddress = PrevPageTable[PrevOffset];

					// Only re-use this page if it was actually rendered to (i.e., mapped during in a render call)
					FPhysicalPageMetaData MetaData = PrevPhysicalPageMetaData[PhysPageAddressToIndex(PrevPhysAddress)];
					if (MetaData.State == VSM_PHYSICAL_PAGE_STATE_RENDERED)
					{
// 'rand robin' invalidation
#if 0
						// If cached for too long invalidate
						if (MetaData.Age > 3 + (PageOffset & 3))
						{
#if VSM_GENERATE_STATS
							InterlockedAdd(OutStatsBuffer[4], 1);
#endif // VSM_GENERATE_STATS
						}
						else
#endif
						{
#if VSM_GENERATE_STATS
							InterlockedAdd(OutStatsBuffer[1], 1);
#endif // VSM_GENERATE_STATS

							CachedPageInfo.PhysPageAddress = PrevPhysAddress;
						}
					}
				}
// Needs more work (must disable page AND ensure fallback page is enabled)!
#if 0
				else
				{
					// Find fallback
					uint PrevIncCoarserPageFlag = PrevPageFlag;
					uint PrevCoarseOffset = 0;
					// Check coarser levels (up to 4 levels away, arbitrary, hardcoded)
					for (uint CoarseMipLevel = MipLevel + 1; CoarseMipLevel < min(MipLevel + 4, VSM_MAX_MIP_LEVELS); ++CoarseMipLevel)
					{
						PrevCoarseOffset = CalcPageOffset(ShadowMapCacheData[ShadowMapID].VirtualShadowMapId, CoarseMipLevel, PrevPageAddress >> (CoarseMipLevel - MipLevel));
						uint PrevCoarserPageFlag = PrevPageFlags[PrevCoarseOffset];
						if (PrevCoarserPageFlag)
						{
							PrevIncCoarserPageFlag = 1;
							break;
						}
					}
					if (PrevIncCoarserPageFlag)
					{
#if VSM_GENERATE_STATS
#endif // VSM_GENERATE_STATS
						InterlockedAdd(OutStatsBuffer[2], 1);
						CachedPageInfo.PhysPageAddress = PrevPageTable[PrevCoarseOffset];
					}
				}
#endif
			}
		}
#endif // HAS_CACHE_DATA

		// Store data that is used later in the process.
		OutCachedPageInfos[pPageIndex] = CachedPageInfo;
		// Request rendering of pages that are not cached (AKA VSM_INVALID_PHYSICAL_PAGE_ADDRESS in cache).
		uint Flags = (CachedPageInfo.PhysPageAddress.x == VSM_INVALID_PHYSICAL_PAGE_ADDRESS ? VSM_INVALID_FLAG : 0) | VSM_ALLOCATED_FLAG;
		OutPageFlags[PageOffset] = Flags;
	}
	else
	{
		OutPageTable[ PageOffset ] = uint2(VSM_INVALID_PHYSICAL_PAGE_ADDRESS, VSM_INVALID_PHYSICAL_PAGE_ADDRESS);
		OutPageFlags[PageOffset] = 0;
	}
}

uint VirtualShadowMapId;
uint TargetMipLevel;

/**
 * Kernel to generate identity mapping that maps virtual pixel addresses back to themselves.
 * Run with a Dispatch size of {Level0DimPagesXY / IDENTITY_MAPPING_CS_GROUP_XY, Level0DimPagesXY / IDENTITY_MAPPING_CS_GROUP_XY, MaxMipLevels}
 */
[numthreads(VSM_DEFAULT_CS_GROUP_XY, VSM_DEFAULT_CS_GROUP_XY, 1)]
void GenerateIdentityMapping(uint3 PageAddressXY_LevelZ : SV_DispatchThreadID)
{
	uint Level = PageAddressXY_LevelZ.z;
	uint2 PageAddress = PageAddressXY_LevelZ.xy;
	if (all(PageAddress < CalcLevelDimsPages(Level)))
	{
		uint PageTableEntryIndex = CalcPageOffset(VirtualShadowMapId, Level, PageAddress);
		if (TargetMipLevel == INDEX_NONE || TargetMipLevel == Level)
		{
			OutPageTable[PageTableEntryIndex] = PageAddress;
			OutPageRequestFlags[PageTableEntryIndex] = 1;
		}
		else
		{
			OutPageTable[PageTableEntryIndex] = uint2(VSM_INVALID_PHYSICAL_PAGE_ADDRESS, VSM_INVALID_PHYSICAL_PAGE_ADDRESS);
			OutPageRequestFlags[PageTableEntryIndex] = 0;
		}
	}
}

Texture2D<UlongType> VisBuffer64;
StructuredBuffer<FVirtualShadowMapProjectionShaderData> ShadowMapProjectionData;
StructuredBuffer<int> VirtualShadowMapIdRemap;
uint NumDirectionalLightSmInds;
uint bPostBasePass;
float LodFootprintScale;
float PageDilationBorderSize;

// Convenience to group up a bunch of data computed for a screen pixel
struct FScreenPixelData
{
	int2 PixelPos;
	float2 ScreenUV;
	float4 ClipPosition;
	float DeviceZ;
	float SceneDepth;
	float3 ViewPosition;
	
	// Note: Actual world position (not pre-translated)
	float3 WorldPosition;

	// NOTE: This data is only valid when executing after the base pass (bPostBasePass is true)
	FGBufferData GBufferData;
};

float2 CalcScreenUV(uint2 PixelPos)
{
	return (float2(PixelPos.xy) + View.ViewRectMin.xy + 0.5f) * View.BufferSizeAndInvSize.zw;
}

// Load DeviceZ from depth buffer (and possibly combine with nanite depth)
float GetDeviceZFromPixel(uint2 PixelPos)
{
	// Merge Nanite depth with depth buffer if enabled (i.e. we're before the base pass)
	float DeviceZ = 0.0f;
#if LOAD_DEPTH_FROM_NANITE_BUFFER
	// Load Nanite Depth
	UlongType VisPixel = VisBuffer64[PixelPos];
	uint DepthInt = 0;
	uint VisibleClusterIndex = 0;
	uint TriIndex = 0;
	UnpackVisPixel(VisPixel, DepthInt, VisibleClusterIndex, TriIndex);

	if (VisibleClusterIndex != 0xFFFFFFFF)
	{
		DeviceZ = asfloat(DepthInt);
	}
#endif // LOAD_DEPTH_FROM_NANITE_BUFFER
	return max(DeviceZ, LookupDeviceZ(CalcScreenUV(PixelPos)));
}

// Use an explicit DeviceZ value for this pixel
FScreenPixelData GetScreenPixelData(uint2 PixelPos, float DeviceZ)
{
	FScreenPixelData Data;
	Data.PixelPos = PixelPos;
	Data.DeviceZ = DeviceZ;
	Data.ScreenUV = CalcScreenUV(PixelPos);
	Data.SceneDepth = ConvertFromDeviceZ(Data.DeviceZ);
	Data.ClipPosition = float4(((Data.ScreenUV.xy - View.ScreenPositionScaleBias.wz) / View.ScreenPositionScaleBias.xy), Data.DeviceZ, 1.0f);

	float4 ViewH = mul(Data.ClipPosition, View.ClipToView);
	Data.ViewPosition = ViewH.xyz / ViewH.w;

	float4 TranslatedWorldH = mul(Data.ClipPosition, View.ClipToTranslatedWorld);
	float3 TranslatedWorldPosition = TranslatedWorldH.xyz / TranslatedWorldH.w;
	// Subtract the view pre-translation to get back to world space
	Data.WorldPosition = TranslatedWorldPosition - View.PreViewTranslation;

	if (bPostBasePass != 0)
	{
		Data.GBufferData = GetGBufferData(Data.ScreenUV);
	}

	return Data;
}

FScreenPixelData GetScreenPixelData(uint2 PixelPos)
{
	return GetScreenPixelData(PixelPos, GetDeviceZFromPixel(PixelPos));
}

uint GetMipLevel(int VirtualShadowMapId, FScreenPixelData Pixel)
{
	float Footprint = float(VSM_VIRTUAL_MAX_RESOLUTION_XY);

	{
		// Compute footprint by projecting the approximate size of a camera pixel at the given depth to shadow space
		// NOTE: This doesn't take the screen XY position/FOV into account, which may or may not be desirable.
		
		// TODO: Roll into a uniform
		float2 RadiusXY = 1.0f / (View.ViewSizeAndInvSize.xy * View.ViewToClip._m00_m11);
		float RadiusScreen = min(RadiusXY.x, RadiusXY.y);
		float DepthScale = Pixel.SceneDepth * View.ViewToClip[2][3] + View.ViewToClip[3][3];

		float RadiusWorld = DepthScale * RadiusScreen;

		float3 TranslatedWorldPosition = Pixel.WorldPosition + ShadowMapProjectionData[VirtualShadowMapId].ShadowPreViewTranslation;
		float4 ShadowUVz = mul(float4(TranslatedWorldPosition, 1.0f), ShadowMapProjectionData[VirtualShadowMapId].TranslatedWorldToShadowUVMatrix);

		float4 RadiusClipH = mul(float4(RadiusWorld, 0.0f, ShadowUVz.w, 1.0f), ShadowMapProjectionData[VirtualShadowMapId].ShadowViewToClipMatrix);
		float RadiusClip = abs(RadiusClipH.x / RadiusClipH.w);
		Footprint = RadiusClip * float(2 * VSM_VIRTUAL_MAX_RESOLUTION_XY);
	}

	return CalcMipLevelFromFootprint(LodFootprintScale * Footprint, VSM_MAX_MIP_LEVELS);
}

void MarkPage(uint VirtualShadowMapId, uint MipLevel, FScreenPixelData Pixel, float2 PageDilationOffset)
{
	FVirtualShadowMapProjectionShaderData ProjectionData = ShadowMapProjectionData[VirtualShadowMapId];
	float4 ShadowUVz = mul(float4(Pixel.WorldPosition + ProjectionData.ShadowPreViewTranslation, 1.0f), ProjectionData.TranslatedWorldToShadowUVMatrix);
	ShadowUVz.xyz /= ShadowUVz.w;

	// Check overlap vs the shadow map space
	// NOTE: XY test not really needed anymore with the precise cone test in the caller, but we'll leave it for the moment
	bool bInClip = ShadowUVz.w > 0.0f && 
		all(ShadowUVz.xyz <= ShadowUVz.w &&
			ShadowUVz.xyz >= float3(-ShadowUVz.ww, 0.0f));
	if (!bInClip)
	{
		return;
	}

	float2 PageAddressFloat = ShadowUVz.xy * CalcLevelDimsPages(MipLevel);
	uint2 PageAddress = uint2(PageAddressFloat);
	uint PageOffset = CalcPageOffset(VirtualShadowMapId, MipLevel, PageAddress);
	OutPageRequestFlags[PageOffset] = 1;

	// PageDilationBorderSize == 0 implies PageDilationOffset.xy == 0
	if (PageDilationBorderSize > 0.0f)
	{
		uint2 PageAddress2 = uint2(PageAddressFloat + PageDilationOffset);
		uint PageOffset2 = CalcPageOffset(VirtualShadowMapId, MipLevel, PageAddress2);
		if (PageOffset2 != PageOffset)
		{
			OutPageRequestFlags[PageOffset2] = 1;
		}
		uint2 PageAddress3 = uint2(max(float2(0, 0), PageAddressFloat - PageDilationOffset));
		uint PageOffset3 = CalcPageOffset(VirtualShadowMapId, MipLevel, PageAddress3);
		if (PageOffset3 != PageOffset)
		{
			OutPageRequestFlags[PageOffset3] = 1;
		}
	}
}

[numthreads(VSM_DEFAULT_CS_GROUP_XY, VSM_DEFAULT_CS_GROUP_XY, 1)]
void GeneratePageFlagsFromPixels(uint3 GroupId : SV_GroupID, uint GroupIndex : SV_GroupIndex, uint3 DispatchThreadId : SV_DispatchThreadID)
{
	// Morton order within a group so page access/atomics are more coherent and wave-swizzled gradients are possible.
	uint2 PixelPos = VSM_DEFAULT_CS_GROUP_XY * GroupId.xy + MortonDecode(GroupIndex);

	if (any(PixelPos >= uint2(View.ViewSizeAndInvSize.xy)))
	{
		return;
	}
	
	FScreenPixelData Pixel = GetScreenPixelData(PixelPos);

	// Dither pattern for page dilation
	// We don't need to to check all 8 adjacent pages; as long as there's at least a single pixel near the edge
	// the adjacent one will get mapped. In practice only checking one diagonal seems to work fine and have minimal
	// overhead.
	float2 PageDilationOffset = PageDilationBorderSize * 
		float2(GroupIndex & 1 ? 1.0f : -1.0f,
			   GroupIndex & 2 ? 1.0f : -1.0f);
		
	// excluding unlit to avoid including processing sky dome
	if (bPostBasePass != 0)
	{
		if (Pixel.GBufferData.ShadingModelID == SHADINGMODELID_UNLIT)
		{
			return;
		}
	}
	
	// Directional lights
	for (uint Index = 0; Index < NumDirectionalLightSmInds; ++Index)
	{
		// Mark one page per directional light. Lights can have varying numbers of clipmap levels allocated which
		// will all be contiguous in the array, so we hop between them using the counts.
		int ClipmapStartId = VirtualShadowMapIdRemap[Index];
		FVirtualShadowMapProjectionShaderData BaseProjectionData = ShadowMapProjectionData[ClipmapStartId];

		// Possibly use a single shadow projection data for the whole clipmap with just scales/biases for
		// each level (to handle snapping). For now we maintain one per level.
		//int ClipmapLevel = CalcClipmapLevel(length(Pixel.WorldPosition - ProjectionData.ClipmapWorldOrigin), ClipmapResolutionLodBias);
		const int ClipmapLevel = CalcClipmapLevel(BaseProjectionData, Pixel.WorldPosition);
		int ClipmapIndex = max(0, ClipmapLevel - BaseProjectionData.ClipmapLevel);
		if (ClipmapIndex < BaseProjectionData.ClipmapLevelCount)
		{
			MarkPage(ClipmapStartId + ClipmapIndex, 0, Pixel, PageDilationOffset);
		}
	}

	// Local lights
	{
		uint EyeIndex = 0; // ??
		uint3 GridCoordinate = ComputeLightGridCellCoordinate(PixelPos, Pixel.SceneDepth, EyeIndex);
		uint GridLinearIndex = ComputeLightGridCellIndex(GridCoordinate, EyeIndex);
		const FCulledLightsGridData CulledLightGridData = GetCulledLightsGrid(GridLinearIndex, EyeIndex);

		LOOP
		for (uint Index = 0; Index < CulledLightGridData.NumLocalLights; ++Index)
		{
			const FLocalLightData LightData = GetLocalLightData(CulledLightGridData.DataStartIndex + Index, EyeIndex);
			const uint LightGridLightIndex = ForwardLightData.CulledLightDataGrid[CulledLightGridData.DataStartIndex + Index];

			float3 ToLight = normalize(LightData.LightPositionAndInvRadius.xyz - Pixel.WorldPosition);
			// Also do precise cone test, since froxels are pretty coarse at times.
			if (dot(ToLight, LightData.LightDirectionAndShadowMask.xyz) < LightData.SpotAnglesAndSourceRadiusPacked.x)
			{
				continue;
			}

			// The Virtual Shadow Remap stores directional lights first
			int VirtualShadowMapId = VirtualShadowMapIdRemap[NumDirectionalLightSmInds + LightGridLightIndex];
			if (VirtualShadowMapId != INDEX_NONE)
			{
				bool bSpotLight = LightData.SpotAnglesAndSourceRadiusPacked.x > -2.0f;
				if( !bSpotLight )
				{
					VirtualShadowMapId += GetCubeFace( ToLight );
				}

				uint MipLevel = GetMipLevel(VirtualShadowMapId, Pixel);
				MarkPage(VirtualShadowMapId, MipLevel, Pixel, PageDilationOffset);
			}
		}
	}
}



RWStructuredBuffer<uint> OutHPageFlags;
RWStructuredBuffer<uint4> PageRectBoundsOut;

[numthreads(VSM_DEFAULT_CS_GROUP_X, 1, 1)]
void InitPageRectBounds(uint3 Index : SV_DispatchThreadID)
{
	if (Index.x < VSM_MAX_MIP_LEVELS * NumShadowMaps)
	{
		PageRectBoundsOut[Index.x] = uint4(VSM_LEVEL0_DIM_PAGES_XY, VSM_LEVEL0_DIM_PAGES_XY, 0, 0);
	}
}

/**
 * One thread per page table flag entry, one vertical grid row per shadow map
 */
[numthreads(VSM_DEFAULT_CS_GROUP_X, 1, 1)]
void GenerateHierarchicalPageFlags(uint2 ThreadId : SV_DispatchThreadID, uint2 GroupId : SV_GroupID)
{
	// early out any overflowing threads.
	if (ThreadId.x >= PageTableSize)
	{
		return;
	}

	uint PageTableEntryIndex = ThreadId.x;
	// Use the group ID to ensure the compiler knows it is scalar / uniform
	uint ShadowMapID = GroupId.y;
	uint GlobalPageTableEntryIndex = ShadowMapID * PageTableSize + PageTableEntryIndex;
	// If the flag is set, let's get on with it

	uint Flag = PageFlags[GlobalPageTableEntryIndex];
	if (Flag)
	{
		// 

		// find the mip-level for this thread.
		uint MipLevel = 0;
		UNROLL
		for (MipLevel = 0; MipLevel < VSM_MAX_MIP_LEVELS - 1; ++MipLevel)
		{
			if (PageTableEntryIndex < CalcLevelOffsets( MipLevel + 1))
			{
				break;
			}
		}
		uint Level0RowMask = ((1U << VSM_LOG2_LEVEL0_DIM_PAGES_XY) - 1U);
		// Offset within level
		uint PageTableLevelOffset = PageTableEntryIndex - CalcLevelOffsets(MipLevel);
		// Coordinate within Mip Level
		uint PX = PageTableLevelOffset & (Level0RowMask >> MipLevel);
		uint PY = PageTableLevelOffset >> (VSM_LOG2_LEVEL0_DIM_PAGES_XY - MipLevel);

		// Compute the min/max rect of active pages
		uint PageBoundIndex = ShadowMapID * VSM_MAX_MIP_LEVELS + MipLevel;
		InterlockedMin(PageRectBoundsOut[PageBoundIndex].x, PX);
		InterlockedMin(PageRectBoundsOut[PageBoundIndex].y, PY);
		InterlockedMax(PageRectBoundsOut[PageBoundIndex].z, PX);
		InterlockedMax(PageRectBoundsOut[PageBoundIndex].w, PY);

		// Loop over H flag levels, this builds a mip pyramid over _each_ mip level in the page table
		// the 0-th level in this hiearchy is the page table mip level itself.
		uint MaxHLevel = VSM_MAX_MIP_LEVELS - MipLevel;
		uint HLevelSizePages = VSM_LEVEL0_DIM_PAGES_XY >> MipLevel;
		// Note: starting from 1 as level 0 is the ordinary flag mip level
		for (uint HMipLevel = 1U; HMipLevel < MaxHLevel; ++HMipLevel)
		{
			HLevelSizePages >>= 1U;
			PX >>= 1U;
			PY >>= 1U;
			uint HPageFlagOffset = ShadowMapID * HPageTableSize 
				+ CalcHPageFlagLevelOffsets(MipLevel)
				+ CalcLevelOffsets(HMipLevel + MipLevel) 
				- CalcLevelOffsets(MipLevel + 1U) 
				+ PY * HLevelSizePages + PX;

			uint PreviousValue = 0;
			InterlockedOr(OutHPageFlags[HPageFlagOffset], Flag, PreviousValue);

			// If this was already the value, then whoever did that will continue up the hierarhcy, best of luck!
			if (PreviousValue == Flag)
			{
				break;
			}
		}
	}
}

RWStructuredBuffer<uint> CoverageSummaryInOut;
StructuredBuffer<uint> PageRequestFlags;

/**
 * One thread per 2x2 page flags in level 0 (aka num in level 1), launched as 1d groups, with 2D grid with Y dim ==  NumShadowMaps.
 */
[numthreads(VSM_DEFAULT_CS_GROUP_X, 1, 1)]
void CreatePageMappings(uint2 ThreadId : SV_DispatchThreadID, uint2 GroupId : SV_GroupID)
{
	const uint NumLevel1Entries = VSM_LEVEL0_DIM_PAGES_XY * VSM_LEVEL0_DIM_PAGES_XY / 4;

	// early out any overflowing threads.
	if (ThreadId.x >= NumLevel1Entries)
	{
		return;
	}

#if VSM_GENERATE_STATS
	if (all(ThreadId == 0))
	{
		OutStatsBuffer[3] = NumShadowMaps;
	}
#endif // VSM_GENERATE_STATS

	uint Level0RowMask = ((1U << VSM_LOG2_LEVEL0_DIM_PAGES_XY) - 1U);

	// Use the group ID to ensure the compiler knows it is scalar / uniform
	uint ShadowMapID = GroupId.y;
	// Get 1D offset in level1
	uint PageTableEntryIndex = ThreadId.x;

	uint2 vPage;
	vPage.x = PageTableEntryIndex & (Level0RowMask >> 1);
	vPage.y = PageTableEntryIndex >> (VSM_LOG2_LEVEL0_DIM_PAGES_XY - 1);

	uint ChildCoverage = 0;

	// Init mip0 pages
	for( uint Child = 0; Child < 4; Child++ )
	{
		uint2 vChildPage = vPage * 2 + uint2( Child & 1, Child >> 1 );

		uint PageOffset = CalcPageOffset( ShadowMapID, 0, vChildPage );
		uint Flag = PageRequestFlags[ PageOffset ];

		CreatePageMapping( ShadowMapID, 0, vChildPage, PageOffset, Flag != 0 );

		ChildCoverage |= Flag << Child;
	}

	uint AllCovered = ChildCoverage;

	for (uint Level = 1; Level < VSM_MAX_MIP_LEVELS; ++Level)
	{
		uint PageOffset = CalcPageOffset( ShadowMapID, Level, vPage );
		uint Flag = PageRequestFlags[ PageOffset ];

		bool bIsAllCovered = AllCovered == 0xf;	//0b1111

		// Don't kill the last mip. It may be forced on.
		if( Level == VSM_MAX_MIP_LEVELS - 1 )
			bIsAllCovered = false;
		
		CreatePageMapping( ShadowMapID, Level, vPage, PageOffset, Flag && !bIsAllCovered );
		
		if( Level == VSM_MAX_MIP_LEVELS - 1 )
			break;
		
		uint2 Child = vPage & 1;
		uint ChildIndex = Child.x + Child.y * 2;
		AllCovered = (Flag || bIsAllCovered) ? (1 << ChildIndex) : 0;
		
		uint PackedCoverage;
		PackedCoverage  = AllCovered;
		PackedCoverage |= 1 << 16;

		vPage >>= 1;
		uint NextOffset = CalcPageOffset( ShadowMapID, Level + 1, vPage );
		
		// Add coverage and retrieve sum + counter
		// Propagate atomically to the next level, to only let last thread to go on we store 1 in upper bits
		uint OtherPackedCoverage = 0;
		InterlockedAdd( CoverageSummaryInOut[ NextOffset ], PackedCoverage, OtherPackedCoverage );

		// 3 out of 4 threads will exit here, as they are done (moving up mip chain they're not needed), only last one will continue.
		// NOTE: this leads to poor utilization but is usually far preferable to multiple passes, also whole SIMDs exit fairly quickly. 
		//       One could probably schedule the threads a bit more intelligently...
		if (OtherPackedCoverage < (3 << 16))
		{
			break;
		}

		// Add the coverage of the first three in 2x2 (returned by atomic).
		PackedCoverage += OtherPackedCoverage;
		
		AllCovered = ( PackedCoverage ) & 0xf;
	}
}


#define LOG2_TILE_SIZE	5
#define LOG2_TILES_PER_PAGE_X ( VSM_LOG2_PAGE_SIZE - LOG2_TILE_SIZE )
#define LOG2_TILES_PER_PAGE_XY ( 2 * LOG2_TILES_PER_PAGE_X )

#define TILES_PER_PAGE_X_MASK ( ( 1 << LOG2_TILES_PER_PAGE_X ) - 1 )
#define TILES_PER_PAGE_XY_MASK ( ( 1 << LOG2_TILES_PER_PAGE_XY ) -1 )

StructuredBuffer<uint> NumAllocatedPhysicalPages;

RWBuffer<uint> ClearPhysicalPagesArgs;
RWTexture2D< uint > PhysicalPagesTexture;

StructuredBuffer<FCachedPageInfo> CachedPageInfos;
Texture2D< uint > CachedPhysicalPagesTexture;

RWStructuredBuffer<FPhysicalPageMetaData> PhysicalPageMetaDataOut;

[numthreads( 1, 1, 1 )]
void InitClearPhysicalPagesArgs(uint3 DTID : SV_DispatchThreadID)
{
	uint PageCount = NumAllocatedPhysicalPages[ 0 ];
	ClearPhysicalPagesArgs[ 0 ] = (PageCount << uint(LOG2_TILES_PER_PAGE_XY));
	ClearPhysicalPagesArgs[ 1 ] = 1;
	ClearPhysicalPagesArgs[ 2 ] = 1;
}

[numthreads( 16, 16, 1 )]
void ClearPhysicalPages( uint3 TileThreadID : SV_GroupThreadID, uint3 TileIndex : SV_GroupID )
{
	const uint PageIndex = TileIndex.x >> uint(LOG2_TILES_PER_PAGE_XY);
	const uint LocalTileIndex = TileIndex.x & uint(TILES_PER_PAGE_XY_MASK);

	const uint LocalTileX = LocalTileIndex & uint(TILES_PER_PAGE_X_MASK);
	const uint LocalTileY = LocalTileIndex >> uint(LOG2_TILES_PER_PAGE_X);

	uint ClearValue[4] = { 0u, 0u, 0u, 0u };

	FPhysicalPageMetaData MetaData;
	MetaData.State = VSM_PHYSICAL_PAGE_STATE_CLEARED;
	MetaData.Age = 0;

#if HAS_CACHE_DATA
	// Load data from cache if available
	FCachedPageInfo CachedPageInfo = CachedPageInfos[PageIndex];
	if (CachedPageInfo.PhysPageAddress.x != VSM_INVALID_PHYSICAL_PAGE_ADDRESS)
	{
		const uint2 TileOffset = (CachedPageInfo.PhysPageAddress << uint2(VSM_LOG2_PAGE_SIZE, VSM_LOG2_PAGE_SIZE)) + (uint2(LocalTileX, LocalTileY) << uint2(LOG2_TILE_SIZE, LOG2_TILE_SIZE));
		const uint2 BasePos = TileOffset + (TileThreadID.xy << 1u);
		ClearValue[0] = asuint(max(0.0f, asfloat(CachedPhysicalPagesTexture[BasePos + uint2(0, 0)]) + CachedPageInfo.DepthOffset));
		ClearValue[1] = asuint(max(0.0f, asfloat(CachedPhysicalPagesTexture[BasePos + uint2(1, 0)]) + CachedPageInfo.DepthOffset));
		ClearValue[2] = asuint(max(0.0f, asfloat(CachedPhysicalPagesTexture[BasePos + uint2(0, 1)]) + CachedPageInfo.DepthOffset));
		ClearValue[3] = asuint(max(0.0f, asfloat(CachedPhysicalPagesTexture[BasePos + uint2(1, 1)]) + CachedPageInfo.DepthOffset));

		MetaData = PrevPhysicalPageMetaData[PhysPageAddressToIndex(CachedPageInfo.PhysPageAddress)];
		// This data has survived one more frame
		MetaData.Age += 1;
	}
#endif // HAS_CACHE_DATA

	const uint PageX = PageIndex & PhysicalPageRowMask;
	const uint PageY = PageIndex >> PhysicalPageRowShift;
	const uint2 TileOffset = (uint2(PageX, PageY) << uint2(VSM_LOG2_PAGE_SIZE, VSM_LOG2_PAGE_SIZE)) + (uint2(LocalTileX, LocalTileY) << uint2(LOG2_TILE_SIZE, LOG2_TILE_SIZE));

	// Update physical page meta data
	if (LocalTileIndex == 0u && all(TileThreadID.xy == 0u))
	{
		PhysicalPageMetaDataOut[PageIndex] = MetaData;
	}

	const uint2 BasePos = TileOffset + (TileThreadID.xy << uint2(1u, 1u));
	PhysicalPagesTexture[BasePos + uint2(0u, 0u)] = ClearValue[0];
	PhysicalPagesTexture[BasePos + uint2(1u, 0u)] = ClearValue[1];
	PhysicalPagesTexture[BasePos + uint2(0u, 1u)] = ClearValue[2];
	PhysicalPagesTexture[BasePos + uint2(1u, 1u)] = ClearValue[3];
}



RWStructuredBuffer<FPhysicalPageMetaData> InOutPhysicalPageMetaData;
StructuredBuffer<uint> VirtualShadowMapFlags;


/**
 * Processes all page tables organized as a linear block, page table entries for mip levels are in a consecutive range,
 * so it makes no difference to this process which shadow map or level is being handled.
 * Run with Dispatch size: {NumVirtualShadowMaps * PageTableSize / VSM_DEFAULT_CS_GROUP_X, 1, 1}
 */
[numthreads(VSM_DEFAULT_CS_GROUP_X, 1, 1)]
void MarkRenderedPhysicalPages(uint3 PageTableEntryIndex : SV_DispatchThreadID)
{
	// Because of launch size rounding we might get here.
	if (PageTableEntryIndex.x >= NumShadowMaps * PageTableSize)
	{
		return;
	}

	uint ShadowMapID = PageTableEntryIndex.x / PageTableSize;

	// This is estupido, should at least use array of IDs to skip all unused ones...
	if (VirtualShadowMapFlags[ShadowMapID] == 0)
	{
		return;
	}

	uint2 pPage = PageTable[PageTableEntryIndex.x];
	if (pPage.x != VSM_INVALID_PHYSICAL_PAGE_ADDRESS)
	{
		uint PageIndex = PhysPageAddressToIndex(pPage);
		FPhysicalPageMetaData MetaData = InOutPhysicalPageMetaData[PageIndex];
		if (MetaData.State != VSM_PHYSICAL_PAGE_STATE_INVALID)
		{
			MetaData.State = VSM_PHYSICAL_PAGE_STATE_RENDERED;
			// NOTE: error condition, add ensure when we have a sensible compiler for GPU...
		}
		InOutPhysicalPageMetaData[PageIndex] = MetaData;
	}
}


/**
 */
[numthreads(VSM_DEFAULT_CS_GROUP_X, 1, 1)]
void InitPhysicalPageMetaData(uint3 Index : SV_DispatchThreadID)
{
	FPhysicalPageMetaData MetaData;
	MetaData.State = VSM_PHYSICAL_PAGE_STATE_INVALID;
	MetaData.Age = 0;

	// Because of launch size rounding we might get here.
	if (Index.x < MaxPhysicalPages)
	{
		PhysicalPageMetaDataOut[Index.x] = MetaData;
	}
}

