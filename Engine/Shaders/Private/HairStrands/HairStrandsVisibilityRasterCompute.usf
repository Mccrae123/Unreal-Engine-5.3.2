// Copyright Epic Games, Inc. All Rights Reserved.

#define HAIR_STRANDS_PARAMETERS 1

#include "../Common.ush"
#include "HairStrandsClusterCommon.ush"
#include "HairStrandsVertexFactoryCommon.ush"
#include "HairStrandsVisibilityCommon.ush"

///////////////////////////////////////////////////////////////////////////
// Common parameters

uint	TileSizeAsShift;
uint	TileSize;
float	RcpTileSize;
uint	SqrTileSize;
int2	TileRes;

uint	NumBinners;
float	RcpNumBinners;
uint	NumRasterizers;
float	RcpNumRasterizers;

uint	MaxRasterCount;
uint	FrameIdMod8;
uint	ResolutionMultiplier;
int2	OutputResolution;
float2	OutputResolutionf;

///////////////////////////////////////////////////////////////////////////

#if SHADER_RASTERCOMPUTE_BINNING || SHADER_RASTERCOMPUTE_COMPACTION || SHADER_RASTERCOMPUTE_RASTER || SHADER_RASTERCOMPUTE_DEPTH_GRID

///////////////////////////////////////////////////////////////////////////
// 
// Wave size
#if SHADER_RASTERCOMPUTE_DEPTH_GRID == 0

#if PERMUTATION_GROUP_SIZE == 64
#define WAVE_SIZE 32
#elif PERMUTATION_GROUP_SIZE == 32
#define WAVE_SIZE 32
#else
#error Unknown group size	
#endif

#endif //SHADER_RASTERCOMPUTE_DEPTH_GRID

///////////////////////////////////////////////////////////////////////////

/* 
// use untyped buffer for segment tiles to reduce VGPR usage - 16 bytes
struct FVisTile
{
	uint PrimOffset;
	uint PrimCount;
	uint TileCoord;
	uint MinDepth;
};
*/
#define VT_SIZE 4

#define VT_PrimOffset 0
#define VT_PrimCount 1
#define VT_Coord 2
#define VT_MinWriteIndex 3

uint PackVisTileCoord(uint2 Coord)
{
	return uint(((Coord.x & 0xff) << 0) | (((Coord.y) & 0xff) << 8));
}

uint2 UppackVisTileCoord(uint Packed)
{
	return uint2(((Packed >> 0) & 0xff), ((Packed >> 8) & 0xff));
}

///////////////////////////////////////////////////////////////////////////

uint			MacroGroupId;
uint			HairMaterialId;


Texture2D<float> SceneDepthTexture;

uint 			VertexCount;
uint 			VertexStart;
float			SampleWeight;

float3 NDCToPixelCoord(float4 InDC)
{
	const float3 NDC = InDC.xyz / InDC.w;
	float2 UV = NDC.xy * ResolvedView.ScreenPositionScaleBias.xy + ResolvedView.ScreenPositionScaleBias.wz;
	return float3(UV * OutputResolution, NDC.z);
}

void CalcHomogenousPos(in uint4 PB, in float3 PBO, out float4 HP, out uint Type)
{
	const FHairControlPoint CP = UnpackHairControlPoint(
		PB,
		PBO,
		HairStrandsVF_Radius,
		HairStrandsVF_RootScale,
		HairStrandsVF_TipScale);

	const float3 WP = mul(float4(CP.Position, 1.0f), HairStrandsVF_LocalToWorldPrimitiveTransform).xyz;
	HP = mul(float4(WP, 1.0f), LWCHackToFloat(PrimaryView.WorldToClip));
	Type = CP.Type;
}

void CalcHomogenousPosAndRad(in uint4 PB, in float3 PBO, out float4 HP, out float Rad)
{
	const FHairControlPoint CP = UnpackHairControlPoint(
		PB,
		PBO,
		HairStrandsVF_Radius,
		HairStrandsVF_RootScale,
		HairStrandsVF_TipScale);

	const float3 WP = mul(float4(CP.Position, 1.0f), HairStrandsVF_LocalToWorldPrimitiveTransform).xyz;
	HP = mul(float4(WP, 1.0f), LWCHackToFloat(PrimaryView.WorldToClip));
	Rad = CP.WorldRadius * 2000.0; // OutputResolutionf.x; //TODO: figure this out correctly?
}

// Line clipping based on "CLIPPING USING HOMOGENEOUS COORDINATES" by Blinn et al.
bool BlinnLineClipping(inout float4 P0, inout float4 P1)
{
	float2 T = float2(0.0f, 1.0f);
	bool bIsRemoved = P0.w < 0.0f && P1.w < 0.0f; // Both points behind near plane

	bool bSign = false;

	UNROLL
	for (uint PlaneIdx = 0; PlaneIdx < 6; ++PlaneIdx)
	{
		// Compute boundary coordinates of both points (w+x, w-x, w+y, w-y, z, w-z)
		bSign = !bSign;
		const uint CompIdx = PlaneIdx / 2;
		const float Sign = bSign ? 1.0f : -1.0f;
		const float WFactor = PlaneIdx != 4 ? 1.0f : 0.0f;
		const float2 BC = WFactor * float2(P0.w, P1.w) + Sign * float2(P0[CompIdx], P1[CompIdx]);

		float Num = BC.x;
		float Denom = BC.x - BC.y;
		bIsRemoved = bIsRemoved || (BC.x < 0.0f && BC.y < 0.0f); // Both points outside the plane
		float Alpha = Num / Denom;
		
		// If the denominator is negative, P0 has a smaller boundary coordinate than P1, so we can assume
		// that P1 is inside the plane (or bIsRemoved is true), so we need to update the alpha for P0.
		// The reverse is true if the denominator is positive.
		if (Denom < 0.0f)
		{
			T.x = max(T.x, Alpha);
		}
		else
		{
			T.y = min(T.y, Alpha);
		}
	}

	if (!bIsRemoved)
	{
		const float4 P0Clipped = lerp(P0, P1, T.x);
		const float4 P1Clipped = lerp(P0, P1, T.y);
		P0 = P0Clipped;
		P1 = P1Clipped;
	}

	return !bIsRemoved;
}

bool ClipRaySegment(float2 AABBMin, float2 AABBMax, inout float4 P0, inout float4 P1)
{
	const bool bP0Outside = any(P0.xy < AABBMin) || any(P0.xy > AABBMax);
	const bool bP1Outside = any(P1.xy < AABBMin) || any(P1.xy > AABBMax);
	if (!bP0Outside && !bP1Outside)
	{
		return true;
	}

	const float2 Origin = P0.xy;
	const float2 Dir = P1.xy - P0.xy;
	const float2 RcpDir = 1.0f / Dir;

	const float2 T0 = (AABBMin - Origin) * RcpDir;
	const float2 T1 = (AABBMax - Origin) * RcpDir;

	const float TMin = max(min(T0.x, T1.x), min(T0.y, T1.y));
	const float TMax = min(max(T0.x, T1.x), max(T0.y, T1.y));

	// Ray intersects the AABB but the segment is completely outside.
	if (TMax < 0.0f)
	{
		return false;
	}

	// No intersection
	if (TMin > TMax)
	{
		return false;
	}

	float4 P0New = P0;
	float4 P1New = P1;
	if (bP0Outside && TMin > 0.0f && TMin < 1.0f)
	{
		P0New = lerp(P0, P1, TMin);
	}
	if (bP1Outside && TMax > 0.0f && TMax < 1.0f)
	{
		P1New = lerp(P0, P1, TMax);
	}
	P0 = P0New;
	P1 = P1New;

	return true;
}

#endif // Common rasetrizer helper function & parameters

///////////////////////////////////////////////////////////////////////////

#if SHADER_RASTERCOMPUTE_DEPTH_GRID

RWTexture2D<uint>	OutVisTileDepthGrid;
RWTexture2D<uint>	OutDepthCovTexture;

groupshared uint group_FurthestDepth; // (4 bytes)

[numthreads(1024, 1, 1)]
void PrepareDepthGridCS(uint dId : SV_DispatchThreadID, uint GroupThreadID : SV_GroupThreadID)
{
	uint tw = TileRes.x;
	uint th = TileRes.y;

	if (GroupThreadID == 0) group_FurthestDepth = 0xffffffff;

	GroupMemoryBarrierWithGroupSync();

	uint t = dId / 1024;

	uint ty = uint((float(t)+0.5) / float(tw));
	uint tx = t - (ty*tw);

	for (uint p = GroupThreadID; p < SqrTileSize; p += 1024)
	{
		if (p < SqrTileSize)
		{
			uint py = (float(p)+0.5) * RcpTileSize;
			uint px = p - (py*TileSize);

			uint2 Coord = uint2(tx * TileSize + px, ty * TileSize + py);

			if (Coord.x < uint(OutputResolution.x) && Coord.y < uint(OutputResolution.y))
			{
				float Depth = SceneDepthTexture.Load(uint3(Coord, 0));
				uint packedDepth = PackHairVisDepthCoverage(Depth, 1.0);

				InterlockedMin(group_FurthestDepth, packedDepth);

				InterlockedMax(OutDepthCovTexture[Coord], packedDepth);
			}
		}
	}

	GroupMemoryBarrierWithGroupSync();

	OutVisTileDepthGrid[uint2(tx, ty)] = group_FurthestDepth;
}

#endif //SHADER_RASTERCOMPUTE_DEPTH_GRID

///////////////////////////////////////////////////////////////////////////

#if SHADER_RASTERCOMPUTE_BINNING

RWTexture2DArray<uint> 				OutVisTileBinningGrid;
Texture2D<uint>						VisTileDepthGrid;
RWBuffer<uint>						OutVisTilePrims;
RWBuffer<uint>						OutVisTileArgs;
RWByteAddressBuffer					OutVisTileData;

// TODO: Without setting a limit, we are sometimes caught in an infinite loop even though this should not happen.
#define DDA_MAX_ITERATIONS 256

struct FDDAContext
{
	float2 Coord;
	float2 DeltaDist;
	float2 Step;
	float2 SideDist;
};

FDDAContext DDACreateContext(float2 RayStart, float2 RayDir)
{
	const float2 RayDirRcp = 1.0f / RayDir;

	FDDAContext Context;
	Context.Coord = floor(RayStart);
	Context.DeltaDist = abs(RayDirRcp);
	Context.Step = sign(RayDir);
	Context.SideDist = (Context.Coord - RayStart + max(Context.Step, 0.0f)) * RayDirRcp;

	return Context;
}

void DDAAdvance(inout FDDAContext Context)
{
	if (Context.SideDist.x < Context.SideDist.y)
	{
		Context.SideDist.x += Context.DeltaDist.x;
		Context.Coord.x += Context.Step.x;
	}
	else
	{
		Context.SideDist.y += Context.DeltaDist.y;
		Context.Coord.y += Context.Step.y;
	}
}

uint LoadOutVisTileData(uint index, uint offset)
{
	return OutVisTileData.Load((((index)) * VT_SIZE * 4) + ((offset) * 4));
}

void StoreOutVisTileData(uint index, uint offset, uint value)
{
	OutVisTileData.Store((((index)) * VT_SIZE * 4) + ((offset) * 4), (value));
}

groupshared uint group_LoopNum;
groupshared uint group_BatchNum;

#define TILES_TO_ALLOCATE_MAX 1024
groupshared uint group_TilesToAllocate[TILES_TO_ALLOCATE_MAX];
groupshared uint group_TilesToAllocateCount;

// The total number of line segments (VertexCount) is divided up equally between N binners - each binner = a workgroup which loops through the designated set segments in batches of 1024
// NB there is still potential to use LDS to prevent/reduce contention when adding segments to the binning grid and this may improve perf

[numthreads(1024, 1, 1)]
void BinningCS(uint DispatchThreadID : SV_DispatchThreadID, uint GroupThreadID : SV_GroupThreadID, uint GroupID : SV_GroupID)
{
	ResolvedView = ResolveView();
	if (GroupThreadID == 0)
	{
#if PERMUTATION_CULLING	
		if (HairStrandsVF_bIsCullingEnable)
		{
			group_BatchNum = (HairStrandsVF_CullingIndirectBuffer[3] + 1023) / 1024;
		}
		else
		{
			group_BatchNum = (VertexCount + 1023) / 1024;
		}
#else
		group_BatchNum = (VertexCount + 1023) / 1024;
#endif
		
		group_LoopNum = (group_BatchNum + (NumBinners - 1)) * RcpNumBinners;
	}

	GroupMemoryBarrierWithGroupSync();

	LOOP
	for (uint LoopIndex = 0; LoopIndex < group_LoopNum; LoopIndex++)
	{
		uint BatchIndex = LoopIndex + (GroupID * group_LoopNum);

		bool bSegValid = (BatchIndex < group_BatchNum);

#if PERMUTATION_CULLING
		uint PrimID = BatchIndex * 1024 + GroupThreadID;
		if (HairStrandsVF_bIsCullingEnable)
		{
			group_BatchNum = (HairStrandsVF_CullingIndirectBuffer[3] + 1023) / 1024;
			bSegValid = bSegValid && (PrimID < (HairStrandsVF_CullingIndirectBuffer[3]));
		}
		else
		{
			bSegValid = bSegValid && (PrimID < (VertexCount));
		}

		if (bSegValid && HairStrandsVF_bIsCullingEnable)
		{
			const uint VertexCountAfterCulling = HairStrandsVF_CullingIndirectBuffer[3];
			uint FetchIndex0 = PrimID;
			if (FetchIndex0 >= (VertexCountAfterCulling-1))
			{
				bSegValid = false;
			}
			else
			{
				uint FetchIndex1 = min(FetchIndex0 + 1, VertexCountAfterCulling - 1);

				uint VertexIndex0 = HairStrandsVF_CullingIndexBuffer[FetchIndex0];
				float LodRadiusScale0 = HairStrandsVF_CullingRadiusScaleBuffer[FetchIndex0];

				uint VertexIndex1 = HairStrandsVF_CullingIndexBuffer[FetchIndex1];
				float LodRadiusScale1 = HairStrandsVF_CullingRadiusScaleBuffer[FetchIndex1];

				if ((LodRadiusScale0 <= 0.0f) || (VertexIndex1 != VertexIndex0 + 1))
				{
					bSegValid = false;
				}
				else
				{
					PrimID = VertexIndex0;
				}
			}
		}
#else
		uint PrimID = BatchIndex * 1024 + GroupThreadID + VertexStart;
		bSegValid = bSegValid && (PrimID < (VertexStart + VertexCount));
#endif

		const uint SegmentCountLayerIdx = GroupID; // Stores number of segments per tile per workgroup.
		const uint TmpSegmentCountLayerIdx = SegmentCountLayerIdx + NumBinners; // Also stores number of segments per tile per workgroup. Used as second counter for this two pass algorithm.
		const uint TileAllocInfoLayerIdx = SegmentCountLayerIdx + NumBinners * 2; // Stores per tile per workgroup allocation info.


		uint NearestDepth = 0;
		float2 TileCoord0F = 0.0f;
		float2 TileCoord1F = 0.0f;

		// Project segment end points and clip them to the screen
		if (bSegValid)
		{
			float4 H0 = 0.0f;
			float4 H1 = 0.0f;
			uint Type = -1;
			CalcHomogenousPos(HairStrandsVF_PositionBuffer[PrimID], HairStrandsVF_PositionOffsetBuffer[0].xyz, H0, Type);

			bool bIsEndCV = (Type == HAIR_CONTROLPOINT_END);
			bSegValid = !bIsEndCV;

			if (bSegValid)
			{
				CalcHomogenousPos(HairStrandsVF_PositionBuffer[PrimID + 1], HairStrandsVF_PositionOffsetBuffer[0].xyz, H1, Type);
				
				// Do clipping in homogenous coordinates
				bSegValid = BlinnLineClipping(H0, H1);

				if (bSegValid)
				{
					float3 SP0 = NDCToPixelCoord(H0);
					float3 SP1 = NDCToPixelCoord(H1);
					SP0.xy *= RcpTileSize;
					SP1.xy *= RcpTileSize;

					// For peace of mind, make sure these are actually clamped to a valid range.
					SP0 = clamp(SP0, 0.0f, float3(TileRes, 1.0f));
					SP1 = clamp(SP1, 0.0f, float3(TileRes, 1.0f));

					NearestDepth = PackHairVisDepthCoverage(max(SP0.z, SP1.z), 1.0f);
					TileCoord0F = SP0.xy;
					TileCoord1F = SP1.xy;
				}
			}
		}

		if (GroupThreadID == 0)
		{
			group_TilesToAllocateCount = 0;
		}

		GroupMemoryBarrierWithGroupSync();
		
		// Increment per workgroup per tile counters and add tiles to be allocated
		if (bSegValid)
		{
			FDDAContext DDAContext = DDACreateContext(TileCoord0F, normalize(TileCoord1F - TileCoord0F));
			const int2 EndCoord = (int2)floor(TileCoord1F);

			for (int DDAIt = 0; DDAIt < DDA_MAX_ITERATIONS; ++DDAIt)
			{
				const int2 TileCoord = (int2)floor(DDAContext.Coord);

				BRANCH
				if (NearestDepth > VisTileDepthGrid[TileCoord])
				{
					uint OldTileSegmentCount;
					InterlockedAdd(OutVisTileBinningGrid[uint3(TileCoord, SegmentCountLayerIdx)], 1, OldTileSegmentCount);

					BRANCH
					if ((OldTileSegmentCount % 1024) == 0)
					{
						uint WritePos;
						InterlockedAdd(group_TilesToAllocateCount, 1, WritePos);
						if (WritePos < TILES_TO_ALLOCATE_MAX)
						{
							group_TilesToAllocate[WritePos] = PackVisTileCoord(TileCoord);
						}
					}
				}

				if (all(TileCoord == EndCoord))
				{
					break;
				}

				DDAAdvance(DDAContext);
			}
		}

		GroupMemoryBarrierWithGroupSync();

		// Allocate tiles
		const uint TilesToAllocateCount = min(TILES_TO_ALLOCATE_MAX, group_TilesToAllocateCount);
		for (uint TileIdx = GroupThreadID; TileIdx < TilesToAllocateCount; TileIdx += 1024)
		{
			const uint PackedTileCoord = group_TilesToAllocate[TileIdx];
			const uint2 TileCoord = UppackVisTileCoord(PackedTileCoord);

			const uint TotalNewWriteCount = OutVisTileBinningGrid[uint3(TileCoord, SegmentCountLayerIdx)];
			const uint TotalOldWriteCount = OutVisTileBinningGrid[uint3(TileCoord, TmpSegmentCountLayerIdx)];

			uint NewTile;
			InterlockedAdd(OutVisTileArgs[0], 1, NewTile);

			StoreOutVisTileData(NewTile, VT_Coord, PackedTileCoord);
			// Round down the count to the start of the tile and later compare against this to decide which tile to write to.
			StoreOutVisTileData(NewTile, VT_MinWriteIndex, TotalNewWriteCount & ~1023u);

			const uint PrevTile = (OutVisTileBinningGrid[uint3(TileCoord, TileAllocInfoLayerIdx)] & 0xffff);

			if (TotalOldWriteCount > 0)
			{
				StoreOutVisTileData(PrevTile, VT_PrimCount, 1024);
			}

			OutVisTileBinningGrid[uint3(TileCoord, TileAllocInfoLayerIdx)] = (PrevTile << 16) | (NewTile & 0xffff);
		}

		GroupMemoryBarrierWithGroupSync();

		// Write PrimID to tiles
		if (bSegValid)
		{
			FDDAContext DDAContext = DDACreateContext(TileCoord0F, normalize(TileCoord1F - TileCoord0F));
			const int2 EndCoord = (int2)floor(TileCoord1F);

			for (int DDAIt = 0; DDAIt < DDA_MAX_ITERATIONS; ++DDAIt)
			{
				const int2 TileCoord = (int2)floor(DDAContext.Coord);

				BRANCH
				if (NearestDepth > VisTileDepthGrid[TileCoord])
				{
					const uint PackedTiles = OutVisTileBinningGrid[uint3(TileCoord, TileAllocInfoLayerIdx)];
					const uint CurTile = (PackedTiles & 0xffff);
					const uint PrevTile = ((PackedTiles >> 16) & 0xffff);

					// Currently we need this to get our write position, but maybe there is a cheaper way to keep track of that?
					uint OldTileSegmentCount;
					InterlockedAdd(OutVisTileBinningGrid[uint3(TileCoord, TmpSegmentCountLayerIdx)], 1, OldTileSegmentCount);

					const bool bWriteToCurTile = OldTileSegmentCount >= LoadOutVisTileData(CurTile, VT_MinWriteIndex);
					const uint LocalWritePos = OldTileSegmentCount % 1024;
					const uint WritePos = (bWriteToCurTile ? CurTile : PrevTile) * 1024 + LocalWritePos;

					OutVisTilePrims[WritePos] = PrimID;

					BRANCH
					if (bWriteToCurTile)
					{
						if ((OldTileSegmentCount + 1) == OutVisTileBinningGrid[uint3(TileCoord, SegmentCountLayerIdx)])
						{
							StoreOutVisTileData(CurTile, VT_PrimCount, (OldTileSegmentCount == 1023) ? 1024 : ((OldTileSegmentCount + 1) % 1024));
						}
					}
				}

				if (all(TileCoord == EndCoord))
				{
					break;
				}

				DDAAdvance(DDAContext);
			}
		}
	}
}
#endif //SHADER_RASTERCOMPUTE_BINNING

///////////////////////////////////////////////////////////////////////////

#if SHADER_RASTERCOMPUTE_COMPACTION

ByteAddressBuffer					VisTileData;
Buffer<uint> 						VisTilePrims;
Buffer<uint> 						VisTileArgs;
RWByteAddressBuffer					OutCompactedVisTileData;
RWBuffer<uint> 						OutCompactedVisTilePrims;
RWBuffer<uint> 						OutCompactedVisTileArgs;

uint LoadVisTileData(uint index, uint offset)
{
	return VisTileData.Load((((index)) * VT_SIZE * 4) + ((offset) * 4));
}

void StoreCompactedVisTileData(uint index, uint offset, uint value)
{
	OutCompactedVisTileData.Store((((index)) * VT_SIZE * 4) + ((offset) * 4), (value));
}

groupshared uint group_TotalPrimCount;
groupshared uint group_PrimWriteOffset;
groupshared uint group_NumTiles;
groupshared uint group_TilesToCompact[1024];

[numthreads(1024, 1, 1)]
void CompactionCS(uint DispatchThreadID : SV_DispatchThreadID, uint GroupThreadID : SV_GroupThreadID, uint2 GroupID : SV_GroupID)
{
	if (GroupThreadID == 0)
	{
		group_TotalPrimCount = 0;
		group_NumTiles = 0;
	}

	GroupMemoryBarrierWithGroupSync();

	const uint NumTiles = VisTileArgs[0];
	const uint PackedCoord = PackVisTileCoord(GroupID);

	// Compute total number of primitives at this tile coordinate
	uint LocalPrimCount = 0;
	{
		for (uint TileIdx = GroupThreadID; TileIdx < NumTiles; TileIdx += 1024)
		{
			const uint TilePackedCoord = LoadVisTileData(TileIdx, VT_Coord);
			if (PackedCoord == TilePackedCoord)
			{
				LocalPrimCount += LoadVisTileData(TileIdx, VT_PrimCount);
				
				uint WritePos;
				InterlockedAdd(group_NumTiles, 1, WritePos);
				if (WritePos < 1024)
				{
					group_TilesToCompact[WritePos] = TileIdx;
				}
			}
		}
	}

	GroupMemoryBarrierWithGroupSync();

	if (LocalPrimCount > 0)
	{
		InterlockedAdd(group_TotalPrimCount, LocalPrimCount);
	}

	GroupMemoryBarrierWithGroupSync();

	const uint TotalPrimCount = group_TotalPrimCount;

	if (TotalPrimCount == 0)
	{
		return;
	}

	// Allocate space
	if (GroupThreadID == 0)
	{
		const uint NumTilesToAllocate = (TotalPrimCount + 1023) / 1024;

		uint FirstCompactedTile;
		InterlockedAdd(OutCompactedVisTileArgs[0], NumTilesToAllocate, FirstCompactedTile);

		group_PrimWriteOffset = FirstCompactedTile * 1024;

		// Initialize new tiles
		for (uint TileIdx = 0; TileIdx < NumTilesToAllocate; ++TileIdx)
		{
			const uint CompactedTile = FirstCompactedTile + TileIdx;

			const uint PrimCount = ((TileIdx * 1024) < TotalPrimCount) ? 1024 : (TotalPrimCount - (TileIdx * 1024));
			StoreCompactedVisTileData(CompactedTile, VT_PrimCount, PrimCount);
			StoreCompactedVisTileData(CompactedTile, VT_Coord, PackedCoord);
		}
	}

	GroupMemoryBarrierWithGroupSync();

	// Copy PrimIDs to compacted memory
	{
		uint CurrentWriteOffset = group_PrimWriteOffset;

		// First process the LDS list of tiles
		const uint NumInputTiles = min(group_NumTiles, 1024);
		for (uint LDSIdx = 0; LDSIdx < NumInputTiles; ++LDSIdx)
		{
			const uint TileIdx = group_TilesToCompact[LDSIdx];

			const uint TilePrimOffset = TileIdx * 1024;
			const uint TilePrimCount = LoadVisTileData(TileIdx, VT_PrimCount);

			if (GroupThreadID < TilePrimCount)
			{
				OutCompactedVisTilePrims[CurrentWriteOffset + GroupThreadID] = VisTilePrims[TilePrimOffset + GroupThreadID];
			}

			CurrentWriteOffset += TilePrimCount;
		}

		// Check any remaning tiles
		if (group_NumTiles > 1024)
		{
			for (uint TileIdx = group_TilesToCompact[1023] + 1; TileIdx < NumTiles; ++TileIdx)
			{
				const uint TilePackedCoord = LoadVisTileData(TileIdx, VT_Coord);
				if (PackedCoord == TilePackedCoord)
				{
					const uint TilePrimOffset = TileIdx * 1024;
					const uint TilePrimCount = LoadVisTileData(TileIdx, VT_PrimCount);

					if (GroupThreadID < TilePrimCount)
					{
						OutCompactedVisTilePrims[CurrentWriteOffset + GroupThreadID] = VisTilePrims[TilePrimOffset + GroupThreadID];
					}

					CurrentWriteOffset += TilePrimCount;
				}
			}
		}
	}
}

#endif // SHADER_RASTERCOMPUTE_COMPACTION

///////////////////////////////////////////////////////////////////////////

#if SHADER_RASTERCOMPUTE_RASTER

// Simple rasterization algorithm that lerps between line endpoints. Is currently more robust than the Wu algorithm
// and optionally supports anti-aliasing similar to the Wu algorithm.
#define RASTER_LINEAR 0 
// Implementation of Wu's line rasterization algorithm. Currently this implementation has tile shaped artifacts when the line segment is
// clipped against the tile which is why we use the simple linear algorithm at the moment.
#define RASTER_WU 1
 // Set to 1 to enable writing to two pixels straddling the line segment when using the linear rasterization algorithm.
#define ENABLE_RASTER_LINEAR_AA 0

#define RASTER_ALGO RASTER_LINEAR

RWTexture2D<uint> 					RWVisTileDepthGrid;
Buffer<uint> 						VisTilePrims;
Buffer<uint> 						VisTileArgs;
RWByteAddressBuffer					RWVisTileData;
Buffer<uint>						VisTileIndirect;

uint LoadRWVisTileData(uint index, uint offset)
{
	return RWVisTileData.Load((((index)) * VT_SIZE * 4) + ((offset) * 4));
}

void StoreRWVisTileData(uint index, uint offset, uint value)
{
	RWVisTileData.Store((((index)) * VT_SIZE * 4) + ((offset) * 4), (value));
}

RWTexture2D<uint> OutHairCountTexture;
RWTexture2D<uint> OutDepthCovTexture;
RWTexture2D<uint> OutPrimMatTexture;


groupshared uint4 group_SubTile[1024]; //(32 x 32 x 4 x 4 bytes = 16k bytes)

groupshared float3 group_PositionOffset;
groupshared float group_ooTileLODScale;

groupshared uint group_LoopNum;
groupshared uint group_TileNum;

groupshared uint group_ThreadsPerSeg;

#define GS_SEGS 320 //this number is limited by group shared memory

groupshared float4 group_SP0[GS_SEGS];
groupshared float4 group_SP1[GS_SEGS];
groupshared float group_Rad0[GS_SEGS];
groupshared float group_Rad1[GS_SEGS];
groupshared uint group_PrimMatID[GS_SEGS];

groupshared uint group_TileIndex;

void PlotInternal(int2 Coords, float AntiAliasingFactor, float4 P0, float4 P1, float Rad0, float Rad1, float SegmentLenSqRcp, uint PackedTileMin, uint PrimMatID)
{
	const int2 IntraTileCoord = Coords - int2(((PackedTileMin >> 0) & 0xffff), ((PackedTileMin >> 16) & 0xffff));

	if (all(IntraTileCoord >= 0) && all(IntraTileCoord < TileSize))
	{
		// Project P onto line segment and compute the lerp alpha between P0 and P1
		// Simplification of:
		// A = P - P0
		// B = P1 - P0
		// Alpha = dot(A, B) / dot(B, B)
		const float2 P = Coords + 0.5f;
		const float Alpha = saturate(dot(P - P0.xy, P1.xy - P0.xy) * SegmentLenSqRcp);
		const float Depth = lerp(P0.z, P1.z, Alpha);
		const uint PackedDepthCov = PackHairVisDepthCoverage(Depth, 1.0f);
		const uint LinearIndex = IntraTileCoord.x + IntraTileCoord.y * TileSize;

		// Write Depth + PrimMatID if depth test against hair depths is passed
		uint OldValue;
		InterlockedMax(group_SubTile[LinearIndex].x, PackedDepthCov, OldValue);
		if (PackedDepthCov > OldValue)
		{
			group_SubTile[LinearIndex].y = PrimMatID;
		}

		// Add hair count if depth test against scene depth is passed
		if (PackedDepthCov > group_SubTile[LinearIndex].w)
		{
			// Alpha value for perspective correct interpolation. We store the reciprocal of w in the w compoennt,
			// so this is a simplification of:
			// (Alpha / w1) / ((1 - Alpha) / w0 + Alpha / w1)
			const float LerpedRcpW = lerp(P0.w, P1.w, Alpha);
			const float PerspectiveAlpha = (Alpha * P1.w) / LerpedRcpW;
			// Divide by W to make thickness dependent on screen space depth? This division was kept from the previous line rasterization algorithm.
			const float Rad = lerp(Rad0, Rad1, PerspectiveAlpha) * LerpedRcpW;

			InterlockedAdd(group_SubTile[LinearIndex].z, min(Rad, 0.5f) * 2.0f * 1000.0f * SampleWeight * AntiAliasingFactor);
		}
	}
}

void Plot(int2 Coord, float FracY, float AntiAliasingFactor, bool bIsSteep, float4 P0, float4 P1, float Rad0, float Rad1, float SegmentLenSqRcp, uint PackedTileMin, uint PrimMatID)
{
	// First pixel
	{
		float AAFactor = AntiAliasingFactor * (1.0f - FracY);

		PlotInternal(bIsSteep ? Coord.yx : Coord.xy, AAFactor, P0, P1, Rad0, Rad1, SegmentLenSqRcp, PackedTileMin, PrimMatID);
	}

	// Second pixel
	{
		float AAFactor = AntiAliasingFactor * FracY;
		Coord.y += 1;

		PlotInternal(bIsSteep ? Coord.yx : Coord.xy, AAFactor, P0, P1, Rad0, Rad1, SegmentLenSqRcp, PackedTileMin, PrimMatID);
	}
}

[numthreads(1024, 1, 1)]
void RasterCS(uint DispatchThreadID : SV_DispatchThreadID, uint GroupThreadID : SV_GroupThreadID, uint GroupID : SV_GroupID)
{
	ResolvedView = ResolveView();

	if (GroupThreadID == 0)
	{
		group_TileNum = VisTileArgs[0];
		group_LoopNum = (float(group_TileNum) + float(NumRasterizers - 1)) * RcpNumRasterizers;

		group_PositionOffset = HairStrandsVF_PositionOffsetBuffer[0].xyz;

		/* no longer in use - keep for ref? Moving these values to group shared memory did seem to reduce VGPRs - more experimentation needed
		group_RadScale = (((HairStrandsVF_TipScale - HairStrandsVF_RootScale) * HairStrandsVF_Radius * OutputResolutionf.x) / 63.0) / 255.0;
		group_RadOffset = (HairStrandsVF_RootScale * HairStrandsVF_Radius * OutputResolutionf.x)/63.0;
		*/
	}

	GroupMemoryBarrierWithGroupSync();

	LOOP
	for (uint LoopIndex = 0; LoopIndex < group_LoopNum; LoopIndex++)
	{
		if (GroupThreadID == 0)
		{
			group_TileIndex = LoopIndex + (GroupID * group_LoopNum);
		}
		
		GroupMemoryBarrierWithGroupSync();

		bool bTileValid = (group_TileIndex < group_TileNum);

		uint PrimOffset = group_TileIndex * 1024;
		uint PrimCount = LoadRWVisTileData(group_TileIndex, VT_PrimCount);

		uint PackedCoord = LoadRWVisTileData(group_TileIndex, VT_Coord);
		uint2 SubTileMin = UppackVisTileCoord(PackedCoord) * TileSize;

		uint PackedTileMin = ((SubTileMin.x & 0xffff) << 0) | ((SubTileMin.y & 0xffff) << 16);

		if (GroupThreadID == 0)
		{
			group_ThreadsPerSeg = 1;

			if (PrimCount <= 512)
				group_ThreadsPerSeg = 2;
			if (PrimCount <= 341)
				group_ThreadsPerSeg = 3;
			if (PrimCount <= 256)
				group_ThreadsPerSeg = 4;
			if (PrimCount <= 204)
				group_ThreadsPerSeg = 5;
			if (PrimCount <= 170)
				group_ThreadsPerSeg = 6;
			if (PrimCount <= 146)
				group_ThreadsPerSeg = 7;
			if (PrimCount <= 128)
				group_ThreadsPerSeg = 8;
			if (PrimCount <= 64)
				group_ThreadsPerSeg = 16;
			if (PrimCount <= 32)
				group_ThreadsPerSeg = 32;
		}
		
		GroupMemoryBarrierWithGroupSync();

		bool bThreadValid = (bTileValid && (GroupThreadID < (PrimCount * group_ThreadsPerSeg)));

		uint WaveCount = ((PrimCount * group_ThreadsPerSeg) + (WAVE_SIZE - 1) ) / WAVE_SIZE;
		uint WaveThreadCount = WaveCount * WAVE_SIZE;

		bool bWaveThreadValid = (bTileValid && (GroupThreadID < WaveThreadCount));

		bool bUseGroupSPs = (bThreadValid && (GroupThreadID < (min(PrimCount, GS_SEGS) * group_ThreadsPerSeg)));

		bool bGenGroupSPs = (bThreadValid && (GroupThreadID < (min(PrimCount, GS_SEGS))));

		if (bGenGroupSPs)
		{
			uint Prim = GroupThreadID;
			uint PrimID = VisTilePrims[PrimOffset + Prim];

			group_PrimMatID[Prim] = PackHairVisPrimitiveMaterialId(PrimID, HairMaterialId);

			CalcHomogenousPosAndRad(HairStrandsVF_PositionBuffer[PrimID], group_PositionOffset, group_SP0[Prim], group_Rad0[Prim]);
			CalcHomogenousPosAndRad(HairStrandsVF_PositionBuffer[PrimID+1], group_PositionOffset, group_SP1[Prim], group_Rad1[Prim]);
		}

		if (bWaveThreadValid)
		{
			for (uint LinearIndex = GroupThreadID; LinearIndex < SqrTileSize; LinearIndex += WaveThreadCount)
			{
				uint2 Coord;

				Coord.y = (float(LinearIndex) + 0.5f) * RcpTileSize;
				Coord.x = LinearIndex - (Coord.y * TileSize);

				Coord += uint2(((PackedTileMin >> 0) & 0xffff), ((PackedTileMin >> 16) & 0xffff));

				group_SubTile[LinearIndex].x = OutDepthCovTexture[Coord];
				group_SubTile[LinearIndex].y = 0;
				group_SubTile[LinearIndex].z = 0;
				group_SubTile[LinearIndex].w = PackHairVisDepthCoverage(SceneDepthTexture.Load(uint3(Coord, 0)), 1.0f);
			}
		}

		GroupMemoryBarrierWithGroupSync();

		if (bThreadValid)
		{
			uint Prim = uint((float(GroupThreadID) + 0.5f) / float(group_ThreadsPerSeg));
			uint PModTPS = GroupThreadID - (Prim * group_ThreadsPerSeg);

			uint PrimMatID;
			float4 SP0;
			float4 SP1;
			float Rad0;
			float Rad1;

			if (bUseGroupSPs)
			{
				PrimMatID = group_PrimMatID[Prim];
				SP0 = group_SP0[Prim];
				SP1 = group_SP1[Prim];
				Rad0 = group_Rad0[Prim];
				Rad1 = group_Rad1[Prim];
			}
			else
			{
				uint PrimID = VisTilePrims[PrimOffset + Prim];
				PrimMatID = PackHairVisPrimitiveMaterialId(PrimID, HairMaterialId);

				CalcHomogenousPosAndRad(HairStrandsVF_PositionBuffer[PrimID], group_PositionOffset, SP0, Rad0);
				CalcHomogenousPosAndRad(HairStrandsVF_PositionBuffer[PrimID + 1], group_PositionOffset, SP1, Rad1);
			}

			// Clipping
			{
				SP0 = float4(NDCToPixelCoord(SP0), 1.0f / SP0.w);
				SP1 = float4(NDCToPixelCoord(SP1), 1.0f / SP1.w);
				
				// Clip against tile
				const float2 TileMin = float2(((PackedTileMin >> 0) & 0xffff), ((PackedTileMin >> 16) & 0xffff));
				const float2 TileMax = TileMin + TileSize;
				// Clip against a slightly smaller bounding box so that the clipped endpoints are safely inside the tile.
				ClipRaySegment(TileMin + 0.25f, TileMax - 0.25f, SP0, SP1);
			}

			const float SegmentLenSqRcp = 1.0f / dot(SP1.xy - SP0.xy, SP1.xy - SP0.xy);

#if RASTER_ALGO == RASTER_LINEAR

			const float2 DeltaAbs = abs(SP1.xy - SP0.xy);
			const uint NumSteps = min((uint)ceil(max(DeltaAbs.x, DeltaAbs.y)) + 1, TileSize + (ENABLE_RASTER_LINEAR_AA ? 1 : 0));
			const float RcpNumSteps = NumSteps > 1 ? (1.0f / (NumSteps - 1)) : 1.0f;
			const bool bIsSteep = DeltaAbs.y > DeltaAbs.x;

			LOOP
			for (int J = PModTPS; J < NumSteps; J += group_ThreadsPerSeg)
			{
				const float Alpha = J * RcpNumSteps;
				const float4 SP = lerp(SP0, SP1, Alpha);

				const float AntiAliasingFactor = 1.0f;
#if !ENABLE_RASTER_LINEAR_AA
				PlotInternal(SP.xy, AntiAliasingFactor, SP0, SP1, Rad0, Rad1, SegmentLenSqRcp, PackedTileMin, PrimMatID);
#else
				const float2 Coord = (bIsSteep ? SP.yx : SP.xy) - 0.5f;
				const float FracY = frac(Coord.y);
				Plot(Coord, FracY, AntiAliasingFactor, bIsSteep, SP0, SP1, Rad0, Rad1, SegmentLenSqRcp, PackedTileMin, PrimMatID);
#endif // !ENABLE_RASTER_LINEAR_AA
			}
#elif RASTER_ALGO == RASTER_WU
			// Wu's line algorithm. Currently this has some weird artifacts when clipping to tiles.
			// TODO: Remove this entirely or fix the artifacts.
			{
				const bool bIsSteep = abs(SP1.y - SP0.y) > abs(SP1.x - SP0.x);

				if (bIsSteep)
				{
					SP0.xy = SP0.yx;
					SP1.xy = SP1.yx;
				}
				if (SP0.x > SP1.x)
				{
					float4 Tmp = SP0;
					SP0 = SP1;
					SP1 = Tmp;
				}

				const float2 D = SP1.xy - SP0.xy;
				const float Gradient = abs(D.x) < 1e-5f ? 1.0f : D.y / D.x;

				float DeltaY = 0.0f;

				// First endpoint
				int2 Px0;
				{
					const float2 SP0Int = SP0.xy - 0.5f; // transform to integer grid with pixel centers at 0.0 instead of 0.5.
					float2 End;
					End.x = floor(SP0Int.x);
					End.y = SP0Int.y + Gradient * (End.x - SP0Int.x);

					const float GapX = 1.0f;// 1.0f - frac(SP0Int.x + 0.5f);

					Px0 = int2(End.x, floor(End.y));
					
					if (PModTPS == 0)
					{
						const float FracY = frac(End.y);
						Plot(Px0, FracY, GapX, bIsSteep, SP0, SP1, Rad0, Rad1, SegmentLenSqRcp, PackedTileMin, PrimMatID);
					}

					DeltaY = End.y + Gradient; // First y-intersection for the main loop
				}

				// Second endpoint
				int2 Px1;
				{
					const float2 SP1Int = SP1.xy - 0.5f; // transform to integer grid with pixel centers at 0.0 instead of 0.5.
					float2 End;
					End.x = floor(SP1Int.x);
					End.y = SP1Int.y + Gradient * (End.x - SP1Int.x);
					const float GapX = 1.0f;// frac(SP1Int.x + 0.5f);

					Px1 = float2(End.x, floor(End.y));

					if (PModTPS == 0)
					{
						const float FracY = frac(End.y);
						Plot(Px1, FracY, GapX, bIsSteep, SP0, SP1, Rad0, Rad1, SegmentLenSqRcp, PackedTileMin, PrimMatID);
					}
				}

				// Main loop
				const int XBegin = Px0.x + 1 + PModTPS;
				const int XEnd = Px1.x;
				DeltaY += PModTPS * Gradient;
				for (int X = XBegin; X < XEnd; X += group_ThreadsPerSeg)
				{
					const int2 Coord = int2(X, floor(DeltaY));
					const float FracY = frac(DeltaY);
					Plot(Coord, FracY, 1.0f, bIsSteep, SP0, SP1, Rad0, Rad1, SegmentLenSqRcp, PackedTileMin, PrimMatID);
					DeltaY += group_ThreadsPerSeg * Gradient;
				}
			}
#endif // RASTER_ALGO == RASTER_LINEAR
		}

		GroupMemoryBarrierWithGroupSync();

		if (bWaveThreadValid) 
		{
			for (uint LinearIndex = GroupThreadID; LinearIndex < SqrTileSize; LinearIndex += WaveThreadCount)
			{
				uint2 Coord;

				Coord.y = (float(LinearIndex) + 0.5f) * RcpTileSize;
				Coord.x = LinearIndex - (Coord.y * TileSize);

				Coord += uint2(((PackedTileMin >> 0) & 0xffff), ((PackedTileMin >> 16) & 0xffff));

				if (group_SubTile[LinearIndex].y != 0)
				{
					uint oldValue;
					InterlockedMax(OutDepthCovTexture[Coord], group_SubTile[LinearIndex].x, oldValue);
					if (group_SubTile[LinearIndex].x > oldValue)
					{
						OutPrimMatTexture[Coord] = group_SubTile[LinearIndex].y;
					}
				}
				InterlockedAdd(OutHairCountTexture[Coord], group_SubTile[LinearIndex].z);
			}
		}

		GroupMemoryBarrierWithGroupSync();
	}
}

#endif //SHADER_RASTERCOMPUTE_RASTER

///////////////////////////////////////////////////////////////////////////

#if SHADER_RASTERCOMPUTE_DEBUG

#include "../ShaderPrint.ush"
void PrintBool(inout FShaderPrintContext Ctx, bool In)
{
	if (In)
	{
		Print(Ctx, TEXT("Yes"), FontGreen);
	}
	else
	{
		Print(Ctx, TEXT("No"), FontRed);
	}
}

Texture2D<uint>						VisTileDepthGrid;
Texture2DArray<uint> 				VisTileBinningGrid;
//Buffer<uint>						OutVisTilePrims;
Buffer<uint>						VisTileArgs;
//ByteAddressBuffer					OutVisTileData;

uint MacroGroupId;
uint PrimitiveInfoIndex;
uint TotalPrimitiveInfoCount;

#define TilePrintOffset (TileSize >> 1)

float4 Transparent(float4 Color) { return float4(Color.xyz, 0.5f); }

uint GetTileTotalSegment(uint2 TileCoord, bool bPrintDetails)
{
	const float TileDisplayScale = 1.5f;
	const uint DisplayTileSize = TileSize * TileDisplayScale;
	uint2 InlinedTileCoord = uint2(0, 0);

	uint TotalSegments = 0;
	const uint BinCount = NumBinners;// * 2; // Each binner fill in 2 bins, see binning algo.
	for (uint BinIt = 0; BinIt < BinCount; ++BinIt)
	{
		const uint CurrTileSegments = VisTileBinningGrid.Load(uint4(TileCoord, BinIt, 0));
		TotalSegments += CurrTileSegments;

		if (bPrintDetails)
		{
			AddFilledQuadSS(InlinedTileCoord * DisplayTileSize, (InlinedTileCoord + 1) * DisplayTileSize, CurrTileSegments > 0 ? Transparent(ColorLightGreen) : Transparent(ColorLightRed));
			AddQuadSS(InlinedTileCoord * DisplayTileSize, (InlinedTileCoord + 1) * DisplayTileSize, ColorYellow);

			FShaderPrintContext Context = InitShaderPrintContext(true, InlinedTileCoord * DisplayTileSize + TilePrintOffset);
			Print(Context, CurrTileSegments, FontWhite);
			++InlinedTileCoord.x;

			// Span details onto 2 lines
			if (BinIt == NumBinners-1)
			{
				InlinedTileCoord.x = 0;
				++InlinedTileCoord.y;
			}
		}
	}
	return TotalSegments;
}

void PrintTile(uint2 TileCoord, uint TotalSegments, bool bPrintText)
{
	AddFilledQuadSS(TileCoord * TileSize, (TileCoord + 1) * TileSize, TotalSegments > 0 ? Transparent(ColorLightGreen) : Transparent(ColorLightRed));
	if (bPrintText)
	{
		FShaderPrintContext Context = InitShaderPrintContext(true, TileCoord * TileSize + uint2(0, TileSize * 1.5f));
		Print(Context, TotalSegments, FontWhite);

		AddQuadSS(TileCoord * TileSize, (TileCoord + 1) * TileSize, ColorYellow);
	}
}

[numthreads(8, 8, 1)]
void MainCS(uint3 ThreadId : SV_DispatchThreadID)
{
	// Info/Stats
	if (all(ThreadId == 0))
	{
		FShaderPrintContext Context = InitShaderPrintContext(true, uint2(50, 110));
		Print(Context, TEXT("Raster compute         "), FontYellow); Newline(Context);
		Print(Context, TEXT("Macro Group Id       : "), FontSilver); Print(Context, MacroGroupId, FontWhite); Newline(Context);
		Print(Context, TEXT("Primitive Info       : "), FontSilver); Print(Context, PrimitiveInfoIndex, FontWhite, 2, 0); Print(Context, TEXT("/"), FontSilver); Print(Context, TotalPrimitiveInfoCount, FontWhite, 2, 0); Newline(Context);
		Newline(Context);

		Print(Context, TEXT("Configuration          "), FontYellow); Newline(Context);
		Print(Context, TEXT("Output Resolution    : "), FontSilver); Print(Context, OutputResolution, FontWhite); Newline(Context);
		Print(Context, TEXT("Resolution Multiplier: "), FontSilver); Print(Context, ResolutionMultiplier, FontWhite); Newline(Context);
		Newline(Context);
		
		Print(Context, TEXT("Tile Size            : "), FontSilver); Print(Context, TileSize, FontWhite); Newline(Context);
		Print(Context, TEXT("Tile Res             : "), FontSilver); Print(Context, TileRes.x, FontWhite, 2, 0); Print(Context, TEXT("x"), FontSilver); Print(Context, TileRes.y, FontWhite, 2, 0); Newline(Context);
		Newline(Context);
		
		Print(Context, TEXT("Num Binners          : "), FontSilver); Print(Context, NumBinners, FontWhite); Newline(Context);
		Print(Context, TEXT("Num Rasterizers      : "), FontSilver); Print(Context, NumRasterizers, FontWhite); Newline(Context);
		Print(Context, TEXT("Max Raster Count     : "), FontSilver); Print(Context, MaxRasterCount, FontWhite); Newline(Context);
		Newline(Context);

		Print(Context, TEXT("Allocated Tile Count : "), FontSilver); Print(Context, VisTileArgs[0], FontWhite); Newline(Context);
		

	}

	// Cursor info	
	if (all(ThreadId == 0) && all(ShaderPrintData.CursorCoord >= 0))
	{
		const uint2 PixelCoord = ShaderPrintData.CursorCoord;
		const uint2 TileCoord  = PixelCoord >> TileSizeAsShift;
	
		const uint TotalSegments = GetTileTotalSegment(TileCoord, true);
		PrintTile(TileCoord, TotalSegments, true);
	}

	// All tile
	{
		const uint2 TileCoord = ThreadId.xy;
		const uint TotalSegments = GetTileTotalSegment(TileCoord, false);
		if (TotalSegments)
		{
			PrintTile(TileCoord, TotalSegments, false);
		}
	}
}
#endif //SHADER_RASTERCOMPUTE_DEBUG

